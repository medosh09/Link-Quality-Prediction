{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2198 entries, 0 to 2197\n",
      "Data columns (total 6 columns):\n",
      "Area          2198 non-null object\n",
      "RSSI          2198 non-null int64\n",
      "SQ            2198 non-null int64\n",
      "ETX           2198 non-null float64\n",
      "Distance      2198 non-null float64\n",
      "Throughput    2198 non-null float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 103.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=pd.read_excel('LQ.xlsx')\n",
    "data.info()\n",
    "grp=data.groupby('Area').count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area\n",
       "ParkLOS           17.760023\n",
       "ParkNLOS          17.929483\n",
       "RESIDENTIAL_IN    18.342404\n",
       "RESIDENTIAL_OD    14.281408\n",
       "TrackLOS          16.268372\n",
       "TrackNLOS         15.889274\n",
       "Name: Throughput, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the maximum throughput in order to calculate TPR\n",
    "maximum=data.groupby(['Area'])['Throughput'].max()\n",
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParkLOS</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.663293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrackLOS</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>15.321800</td>\n",
       "      <td>12.887519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParkNLOS</td>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.807500</td>\n",
       "      <td>5.449338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESIDENTIAL_IN</td>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParkLOS</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185362</td>\n",
       "      <td>13.563479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area  RSSI   SQ       ETX   Distance  Throughput\n",
       "0         ParkLOS    81  100  1.000000   0.000000   13.663293\n",
       "1        TrackLOS    79  100  1.111111  15.321800   12.887519\n",
       "2        ParkNLOS    44   78  1.000000  49.807500    5.449338\n",
       "3  RESIDENTIAL_IN    72  100  1.000000   0.000000   12.904800\n",
       "4         ParkLOS    78  100  1.000000   0.185362   13.563479"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB044BC88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB04D6940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB04FACF8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0528278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB054D7F0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0572D68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB05A4320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB05CB8D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB05CB908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB06223C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB064C940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0675EB8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB06A5470>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB06CB9E8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB06F4F60>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0726518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB074EA90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0781048>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB07A75C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB07CEB38>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB07FF0F0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0827668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0850BE0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB0881198>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000027BB08A8710>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParkLOS</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.663293</td>\n",
       "      <td>0.769329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrackLOS</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>15.321800</td>\n",
       "      <td>12.887519</td>\n",
       "      <td>0.792182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParkNLOS</td>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.807500</td>\n",
       "      <td>5.449338</td>\n",
       "      <td>0.303932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESIDENTIAL_IN</td>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.904800</td>\n",
       "      <td>0.703550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParkLOS</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185362</td>\n",
       "      <td>13.563479</td>\n",
       "      <td>0.763708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area  RSSI   SQ       ETX   Distance  Throughput       TPR\n",
       "0         ParkLOS    81  100  1.000000   0.000000   13.663293  0.769329\n",
       "1        TrackLOS    79  100  1.111111  15.321800   12.887519  0.792182\n",
       "2        ParkNLOS    44   78  1.000000  49.807500    5.449338  0.303932\n",
       "3  RESIDENTIAL_IN    72  100  1.000000   0.000000   12.904800  0.703550\n",
       "4         ParkLOS    78  100  1.000000   0.185362   13.563479  0.763708"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TPR']=0\n",
    "data.loc[data.Area=='ParkLOS', ['TPR']]=data['Throughput']/maximum.ParkLOS\n",
    "data.loc[data.Area=='ParkNLOS', ['TPR']]=data['Throughput']/maximum.ParkNLOS\n",
    "data.loc[data.Area=='RESIDENTIAL_OD', ['TPR']]=data['Throughput']/maximum.RESIDENTIAL_OD\n",
    "data.loc[data.Area=='RESIDENTIAL_IN', ['TPR']]=data['Throughput']/maximum.RESIDENTIAL_IN\n",
    "\n",
    "data.loc[data.Area=='TrackLOS', ['TPR']]=data['Throughput']/maximum.TrackLOS\n",
    "data.loc[data.Area=='TrackNLOS', ['TPR']]=data['Throughput']/maximum.TrackNLOS\n",
    "\n",
    "data.describe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('LQdata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area          2198\n",
       "RSSI          2198\n",
       "SQ            2198\n",
       "ETX           2198\n",
       "Distance      2198\n",
       "Throughput    2198\n",
       "TPR           2198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Area_ParkLOS</th>\n",
       "      <th>Area_ParkNLOS</th>\n",
       "      <th>Area_RESIDENTIAL_IN</th>\n",
       "      <th>Area_RESIDENTIAL_OD</th>\n",
       "      <th>Area_TrackLOS</th>\n",
       "      <th>Area_TrackNLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.663293</td>\n",
       "      <td>0.769329</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>15.321800</td>\n",
       "      <td>12.887519</td>\n",
       "      <td>0.792182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.807500</td>\n",
       "      <td>5.449338</td>\n",
       "      <td>0.303932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.904800</td>\n",
       "      <td>0.703550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185362</td>\n",
       "      <td>13.563479</td>\n",
       "      <td>0.763708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RSSI   SQ       ETX   Distance  Throughput       TPR  Area_ParkLOS  \\\n",
       "0    81  100  1.000000   0.000000   13.663293  0.769329             1   \n",
       "1    79  100  1.111111  15.321800   12.887519  0.792182             0   \n",
       "2    44   78  1.000000  49.807500    5.449338  0.303932             0   \n",
       "3    72  100  1.000000   0.000000   12.904800  0.703550             0   \n",
       "4    78  100  1.000000   0.185362   13.563479  0.763708             1   \n",
       "\n",
       "   Area_ParkNLOS  Area_RESIDENTIAL_IN  Area_RESIDENTIAL_OD  Area_TrackLOS  \\\n",
       "0              0                    0                    0              0   \n",
       "1              0                    0                    0              1   \n",
       "2              1                    0                    0              0   \n",
       "3              0                    1                    0              0   \n",
       "4              0                    0                    0              0   \n",
       "\n",
       "   Area_TrackNLOS  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data=pd.get_dummies(data)\n",
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13925588881722453"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=['RSSI', 'SQ','ETX','Distance','Area_ParkLOS','Area_ParkNLOS','Area_RESIDENTIAL_IN','Area_RESIDENTIAL_OD','Area_TrackLOS','Area_TrackNLOS']\n",
    "X=encoded_data[feature]\n",
    "y=encoded_data['TPR']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=100,test_size=0.20)\n",
    "X_train.shape[1]\n",
    "y_test.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Area_ParkLOS</th>\n",
       "      <th>Area_ParkNLOS</th>\n",
       "      <th>Area_RESIDENTIAL_IN</th>\n",
       "      <th>Area_RESIDENTIAL_OD</th>\n",
       "      <th>Area_TrackLOS</th>\n",
       "      <th>Area_TrackNLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>-0.532552</td>\n",
       "      <td>0.107608</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>1.778417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>-0.856909</td>\n",
       "      <td>-2.346020</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>2.135698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.208194</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.505393</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.494283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>-0.402809</td>\n",
       "      <td>0.189396</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>1.490608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RSSI        SQ       ETX  Distance  Area_ParkLOS  Area_ParkNLOS  \\\n",
       "1663 -0.532552  0.107608 -0.282099  1.778417             0              0   \n",
       "1699 -0.856909 -2.346020 -0.282099  2.135698             0              0   \n",
       "960  -0.208194  0.598333 -0.282099  0.015075             0              0   \n",
       "1434  0.505393  0.680121 -0.282099 -0.494283             0              0   \n",
       "1634 -0.402809  0.189396  0.404499  1.490608             0              0   \n",
       "\n",
       "      Area_RESIDENTIAL_IN  Area_RESIDENTIAL_OD  Area_TrackLOS  Area_TrackNLOS  \n",
       "1663                    0                    1              0               0  \n",
       "1699                    0                    1              0               0  \n",
       "960                     0                    0              1               0  \n",
       "1434                    0                    1              0               0  \n",
       "1634                    0                    1              0               0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization\n",
    "feature1=['RSSI', 'SQ','ETX','Distance']\n",
    "mean=X_train[feature1].mean(axis=0)\n",
    "std=X_train[feature1].std(axis=0)\n",
    "\n",
    "#Normalization of train dataset\n",
    "X_train[feature1]=X_train[feature1]-mean\n",
    "X_train[feature1]=X_train[feature1]/std\n",
    "\n",
    "#Normalization of test dataset\n",
    "X_test[feature1]=X_test[feature1]-mean\n",
    "X_test[feature1]=X_test[feature1]/std\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Area_ParkLOS</th>\n",
       "      <th>Area_ParkNLOS</th>\n",
       "      <th>Area_RESIDENTIAL_IN</th>\n",
       "      <th>Area_RESIDENTIAL_OD</th>\n",
       "      <th>Area_TrackLOS</th>\n",
       "      <th>Area_TrackNLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>0.404076</td>\n",
       "      <td>0.894777</td>\n",
       "      <td>0.494939</td>\n",
       "      <td>0.815268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>0.345652</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>0.494939</td>\n",
       "      <td>0.878605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.984968</td>\n",
       "      <td>0.494939</td>\n",
       "      <td>0.502672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.591032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494939</td>\n",
       "      <td>0.412376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.427445</td>\n",
       "      <td>0.909809</td>\n",
       "      <td>0.507257</td>\n",
       "      <td>0.764247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RSSI        SQ       ETX  Distance  Area_ParkLOS  Area_ParkNLOS  \\\n",
       "1663  0.404076  0.894777  0.494939  0.815268           0.0            0.0   \n",
       "1699  0.345652  0.443823  0.494939  0.878605           0.0            0.0   \n",
       "960   0.462500  0.984968  0.494939  0.502672           0.0            0.0   \n",
       "1434  0.591032  1.000000  0.494939  0.412376           0.0            0.0   \n",
       "1634  0.427445  0.909809  0.507257  0.764247           0.0            0.0   \n",
       "\n",
       "      Area_RESIDENTIAL_IN  Area_RESIDENTIAL_OD  Area_TrackLOS  Area_TrackNLOS  \n",
       "1663                  0.0                  1.0            0.0             0.0  \n",
       "1699                  0.0                  1.0            0.0             0.0  \n",
       "960                   0.0                  0.0            1.0             0.0  \n",
       "1434                  0.0                  1.0            0.0             0.0  \n",
       "1634                  0.0                  1.0            0.0             0.0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#reprocessing the data for AE\n",
    "feature1=['RSSI', 'SQ','ETX','Distance']\n",
    "maxi=X_train[feature1].max(axis=0) \n",
    "\n",
    "#Scaling of train dataset\n",
    "X_train[feature1]=X_train[feature1]/maxi\n",
    "\n",
    "mini=X_train[feature1].min(axis=0)\n",
    "\n",
    "#NScaling of test dataset\n",
    "X_test[feature1]=X_test[feature1]/maxi\n",
    "mini_test=X_test[feature1].min(axis=0)\n",
    "\n",
    "#Scaleup of  dataset\n",
    "scale_values=[1, 7, 1, 1]\n",
    "scalar = pd.Series(scale_values, index=feature1)\n",
    "X_train[feature1]=X_train[feature1]+scalar\n",
    "X_test[feature1]=X_test[feature1]+scalar\n",
    "\n",
    "\n",
    "maxi_1=X_train.max(axis=0)\n",
    "X_train=X_train/maxi_1\n",
    "X_test=X_test/maxi_1\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1406 samples, validate on 352 samples\n",
      "Epoch 1/500\n",
      "1406/1406 [==============================] - 1s 627us/step - loss: 0.2792 - mean_absolute_error: 0.4853 - val_loss: 0.2025 - val_mean_absolute_error: 0.4008\n",
      "Epoch 2/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.1528 - mean_absolute_error: 0.3351 - val_loss: 0.0688 - val_mean_absolute_error: 0.2122\n",
      "Epoch 3/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0477 - mean_absolute_error: 0.1789 - val_loss: 0.0378 - val_mean_absolute_error: 0.1611\n",
      "Epoch 4/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0366 - mean_absolute_error: 0.1613 - val_loss: 0.0358 - val_mean_absolute_error: 0.1561\n",
      "Epoch 5/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0347 - mean_absolute_error: 0.1568 - val_loss: 0.0342 - val_mean_absolute_error: 0.1520\n",
      "Epoch 6/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0329 - mean_absolute_error: 0.1528 - val_loss: 0.0324 - val_mean_absolute_error: 0.1475\n",
      "Epoch 7/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0313 - mean_absolute_error: 0.1486 - val_loss: 0.0310 - val_mean_absolute_error: 0.1437\n",
      "Epoch 8/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0297 - mean_absolute_error: 0.1445 - val_loss: 0.0290 - val_mean_absolute_error: 0.1386\n",
      "Epoch 9/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0282 - mean_absolute_error: 0.1407 - val_loss: 0.0283 - val_mean_absolute_error: 0.1359\n",
      "Epoch 10/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0265 - mean_absolute_error: 0.1358 - val_loss: 0.0256 - val_mean_absolute_error: 0.1294\n",
      "Epoch 11/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0251 - mean_absolute_error: 0.1314 - val_loss: 0.0245 - val_mean_absolute_error: 0.1257\n",
      "Epoch 12/500\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.0339 - mean_absolute_error: 0.154 - 0s 36us/step - loss: 0.0236 - mean_absolute_error: 0.1270 - val_loss: 0.0230 - val_mean_absolute_error: 0.1211\n",
      "Epoch 13/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0222 - mean_absolute_error: 0.1223 - val_loss: 0.0215 - val_mean_absolute_error: 0.1165\n",
      "Epoch 14/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0209 - mean_absolute_error: 0.1178 - val_loss: 0.0203 - val_mean_absolute_error: 0.1123\n",
      "Epoch 15/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0197 - mean_absolute_error: 0.1135 - val_loss: 0.0193 - val_mean_absolute_error: 0.1085\n",
      "Epoch 16/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0188 - mean_absolute_error: 0.1099 - val_loss: 0.0186 - val_mean_absolute_error: 0.1055\n",
      "Epoch 17/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0180 - mean_absolute_error: 0.1068 - val_loss: 0.0178 - val_mean_absolute_error: 0.1028\n",
      "Epoch 18/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0174 - mean_absolute_error: 0.1041 - val_loss: 0.0175 - val_mean_absolute_error: 0.1008\n",
      "Epoch 19/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0169 - mean_absolute_error: 0.1019 - val_loss: 0.0174 - val_mean_absolute_error: 0.0998\n",
      "Epoch 20/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0167 - mean_absolute_error: 0.1006 - val_loss: 0.0166 - val_mean_absolute_error: 0.0975\n",
      "Epoch 21/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0164 - mean_absolute_error: 0.0995 - val_loss: 0.0162 - val_mean_absolute_error: 0.0962\n",
      "Epoch 22/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0162 - mean_absolute_error: 0.0983 - val_loss: 0.0160 - val_mean_absolute_error: 0.0956\n",
      "Epoch 23/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0162 - mean_absolute_error: 0.0979 - val_loss: 0.0160 - val_mean_absolute_error: 0.0953\n",
      "Epoch 24/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0161 - mean_absolute_error: 0.0977 - val_loss: 0.0163 - val_mean_absolute_error: 0.0955\n",
      "Epoch 25/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0160 - mean_absolute_error: 0.0974 - val_loss: 0.0162 - val_mean_absolute_error: 0.0952\n",
      "Epoch 26/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0160 - mean_absolute_error: 0.0968 - val_loss: 0.0160 - val_mean_absolute_error: 0.0947\n",
      "Epoch 27/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0160 - mean_absolute_error: 0.0970 - val_loss: 0.0163 - val_mean_absolute_error: 0.0949\n",
      "Epoch 28/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0160 - mean_absolute_error: 0.0968 - val_loss: 0.0162 - val_mean_absolute_error: 0.0948\n",
      "Epoch 29/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0159 - mean_absolute_error: 0.0966 - val_loss: 0.0162 - val_mean_absolute_error: 0.0948\n",
      "Epoch 30/500\n",
      "1406/1406 [==============================] - 0s 29us/step - loss: 0.0161 - mean_absolute_error: 0.0973 - val_loss: 0.0168 - val_mean_absolute_error: 0.0960\n",
      "Epoch 31/500\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_error: 0.076 - 0s 40us/step - loss: 0.0160 - mean_absolute_error: 0.0965 - val_loss: 0.0161 - val_mean_absolute_error: 0.0944\n",
      "Epoch 32/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0160 - mean_absolute_error: 0.0966 - val_loss: 0.0159 - val_mean_absolute_error: 0.0941\n",
      "Epoch 33/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0159 - mean_absolute_error: 0.0964 - val_loss: 0.0168 - val_mean_absolute_error: 0.0959\n",
      "Epoch 34/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0161 - val_mean_absolute_error: 0.0944\n",
      "Epoch 35/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0159 - mean_absolute_error: 0.0964 - val_loss: 0.0160 - val_mean_absolute_error: 0.0942\n",
      "Epoch 36/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0160 - mean_absolute_error: 0.0966 - val_loss: 0.0158 - val_mean_absolute_error: 0.0939\n",
      "Epoch 37/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0159 - mean_absolute_error: 0.0962 - val_loss: 0.0158 - val_mean_absolute_error: 0.0939\n",
      "Epoch 38/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0159 - mean_absolute_error: 0.0967 - val_loss: 0.0164 - val_mean_absolute_error: 0.0948\n",
      "Epoch 39/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0159 - mean_absolute_error: 0.0963 - val_loss: 0.0158 - val_mean_absolute_error: 0.0938\n",
      "Epoch 40/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0159 - mean_absolute_error: 0.0962 - val_loss: 0.0161 - val_mean_absolute_error: 0.0941\n",
      "Epoch 41/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0159 - mean_absolute_error: 0.0960 - val_loss: 0.0166 - val_mean_absolute_error: 0.0952\n",
      "Epoch 42/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0167 - val_mean_absolute_error: 0.0956\n",
      "Epoch 43/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0159 - mean_absolute_error: 0.0962 - val_loss: 0.0167 - val_mean_absolute_error: 0.0955\n",
      "Epoch 44/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0160 - mean_absolute_error: 0.0963 - val_loss: 0.0164 - val_mean_absolute_error: 0.0948\n",
      "Epoch 45/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0159 - mean_absolute_error: 0.0962 - val_loss: 0.0158 - val_mean_absolute_error: 0.0937\n",
      "Epoch 46/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0164 - val_mean_absolute_error: 0.0949\n",
      "Epoch 47/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0156 - val_mean_absolute_error: 0.0937\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0157 - val_mean_absolute_error: 0.0936\n",
      "Epoch 49/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0160 - val_mean_absolute_error: 0.0941\n",
      "Epoch 50/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0156 - val_mean_absolute_error: 0.0936\n",
      "Epoch 51/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0157 - val_mean_absolute_error: 0.0936\n",
      "Epoch 52/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0160 - val_mean_absolute_error: 0.0940\n",
      "Epoch 53/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0159 - mean_absolute_error: 0.0963 - val_loss: 0.0161 - val_mean_absolute_error: 0.0941\n",
      "Epoch 54/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0159 - mean_absolute_error: 0.0961 - val_loss: 0.0157 - val_mean_absolute_error: 0.0936\n",
      "Epoch 55/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 56/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0158 - val_mean_absolute_error: 0.0935\n",
      "Epoch 57/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0161 - val_mean_absolute_error: 0.0941\n",
      "Epoch 58/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0157 - val_mean_absolute_error: 0.0934\n",
      "Epoch 59/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 60/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0164 - val_mean_absolute_error: 0.0946\n",
      "Epoch 61/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 62/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0159 - mean_absolute_error: 0.0961 - val_loss: 0.0156 - val_mean_absolute_error: 0.0934\n",
      "Epoch 63/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0159 - mean_absolute_error: 0.0962 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 64/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0158 - mean_absolute_error: 0.0957 - val_loss: 0.0159 - val_mean_absolute_error: 0.0937\n",
      "Epoch 65/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0157 - val_mean_absolute_error: 0.0933\n",
      "Epoch 66/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0159 - mean_absolute_error: 0.0960 - val_loss: 0.0154 - val_mean_absolute_error: 0.0935\n",
      "Epoch 67/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 68/500\n",
      "1406/1406 [==============================] - 0s 29us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 69/500\n",
      "1406/1406 [==============================] - 0s 31us/step - loss: 0.0158 - mean_absolute_error: 0.0956 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 70/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 71/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0163 - val_mean_absolute_error: 0.0944\n",
      "Epoch 72/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0162 - val_mean_absolute_error: 0.0943\n",
      "Epoch 73/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0159 - mean_absolute_error: 0.0964 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 74/500\n",
      "1406/1406 [==============================] - 0s 36us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0164 - val_mean_absolute_error: 0.0948\n",
      "Epoch 75/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0166 - val_mean_absolute_error: 0.0950\n",
      "Epoch 76/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0159 - mean_absolute_error: 0.0967 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 77/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0161 - val_mean_absolute_error: 0.0938\n",
      "Epoch 78/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0159 - mean_absolute_error: 0.0964 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 79/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0160 - mean_absolute_error: 0.0964 - val_loss: 0.0157 - val_mean_absolute_error: 0.0933\n",
      "Epoch 80/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0158 - mean_absolute_error: 0.0963 - val_loss: 0.0170 - val_mean_absolute_error: 0.0959\n",
      "Epoch 81/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0165 - val_mean_absolute_error: 0.0949\n",
      "Epoch 82/500\n",
      "1406/1406 [==============================] - 0s 56us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 83/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 84/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0159 - val_mean_absolute_error: 0.0936\n",
      "Epoch 85/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 86/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0957 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 87/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 88/500\n",
      "1406/1406 [==============================] - 0s 36us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 89/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0158 - mean_absolute_error: 0.0963 - val_loss: 0.0161 - val_mean_absolute_error: 0.0939\n",
      "Epoch 90/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0163 - val_mean_absolute_error: 0.0943\n",
      "Epoch 91/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 92/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 93/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 94/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 95/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0154 - val_mean_absolute_error: 0.0935\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 31us/step - loss: 0.0160 - mean_absolute_error: 0.0967 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 97/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0158 - mean_absolute_error: 0.0963 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 98/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0954 - val_loss: 0.0153 - val_mean_absolute_error: 0.0932\n",
      "Epoch 99/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0159 - mean_absolute_error: 0.0966 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 100/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0157 - val_mean_absolute_error: 0.0930\n",
      "Epoch 101/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0154 - val_mean_absolute_error: 0.0932\n",
      "Epoch 102/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0158 - mean_absolute_error: 0.0963 - val_loss: 0.0158 - val_mean_absolute_error: 0.0931\n",
      "Epoch 103/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0157 - mean_absolute_error: 0.0961 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 104/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 105/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0159 - mean_absolute_error: 0.0964 - val_loss: 0.0159 - val_mean_absolute_error: 0.0933\n",
      "Epoch 106/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0161 - val_mean_absolute_error: 0.0938\n",
      "Epoch 107/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0157 - val_mean_absolute_error: 0.0930\n",
      "Epoch 108/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 109/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0154 - val_mean_absolute_error: 0.0927\n",
      "Epoch 110/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0157 - mean_absolute_error: 0.0962 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 111/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0157 - mean_absolute_error: 0.0959 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 112/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 113/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0155 - val_mean_absolute_error: 0.0927\n",
      "Epoch 114/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 115/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 116/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 117/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0963 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 118/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 119/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 120/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0173 - val_mean_absolute_error: 0.0969\n",
      "Epoch 121/500\n",
      "1406/1406 [==============================] - 0s 57us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 122/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 123/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0155 - val_mean_absolute_error: 0.0928\n",
      "Epoch 124/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n",
      "Epoch 125/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 126/500\n",
      "1406/1406 [==============================] - 0s 31us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0153 - val_mean_absolute_error: 0.0933\n",
      "Epoch 127/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 128/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0157 - mean_absolute_error: 0.0959 - val_loss: 0.0164 - val_mean_absolute_error: 0.0947\n",
      "Epoch 129/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0165 - val_mean_absolute_error: 0.0947\n",
      "Epoch 130/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0159 - mean_absolute_error: 0.0960 - val_loss: 0.0154 - val_mean_absolute_error: 0.0930\n",
      "Epoch 131/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0161 - val_mean_absolute_error: 0.0940\n",
      "Epoch 132/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 133/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0960 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 134/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0158 - mean_absolute_error: 0.0959 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 135/500\n",
      "1406/1406 [==============================] - 0s 29us/step - loss: 0.0158 - mean_absolute_error: 0.0958 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 136/500\n",
      "1406/1406 [==============================] - 0s 28us/step - loss: 0.0157 - mean_absolute_error: 0.0959 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 137/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0165 - val_mean_absolute_error: 0.0947\n",
      "Epoch 138/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0158 - mean_absolute_error: 0.0962 - val_loss: 0.0158 - val_mean_absolute_error: 0.0933\n",
      "Epoch 139/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0162 - val_mean_absolute_error: 0.0941\n",
      "Epoch 140/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0161 - val_mean_absolute_error: 0.0938\n",
      "Epoch 141/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 142/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0154 - val_mean_absolute_error: 0.0934\n",
      "Epoch 143/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 145/500\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0163 - val_mean_absolute_error: 0.0942\n",
      "Epoch 146/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 147/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0159 - mean_absolute_error: 0.0965 - val_loss: 0.0163 - val_mean_absolute_error: 0.0944\n",
      "Epoch 148/500\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 149/500\n",
      "1406/1406 [==============================] - 0s 57us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 150/500\n",
      "1406/1406 [==============================] - 0s 57us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0154 - val_mean_absolute_error: 0.0939\n",
      "Epoch 151/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0158 - mean_absolute_error: 0.0964 - val_loss: 0.0159 - val_mean_absolute_error: 0.0937\n",
      "Epoch 152/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 153/500\n",
      "1406/1406 [==============================] - 0s 57us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0154 - val_mean_absolute_error: 0.0933\n",
      "Epoch 154/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0157 - mean_absolute_error: 0.0959 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 155/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0154 - val_mean_absolute_error: 0.0930\n",
      "Epoch 156/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0157 - val_mean_absolute_error: 0.0934\n",
      "Epoch 157/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0159 - mean_absolute_error: 0.0958 - val_loss: 0.0162 - val_mean_absolute_error: 0.0943\n",
      "Epoch 158/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n",
      "Epoch 159/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0156 - mean_absolute_error: 0.0957 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 160/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0933\n",
      "Epoch 161/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 162/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0153 - val_mean_absolute_error: 0.0936\n",
      "Epoch 163/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0157 - mean_absolute_error: 0.0963 - val_loss: 0.0159 - val_mean_absolute_error: 0.0936\n",
      "Epoch 164/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0157 - mean_absolute_error: 0.0962 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 165/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 166/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 167/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0156 - mean_absolute_error: 0.0952 - val_loss: 0.0153 - val_mean_absolute_error: 0.0931\n",
      "Epoch 168/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0156 - mean_absolute_error: 0.0957 - val_loss: 0.0167 - val_mean_absolute_error: 0.0955\n",
      "Epoch 169/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0165 - val_mean_absolute_error: 0.0950\n",
      "Epoch 170/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0158 - mean_absolute_error: 0.0956 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 171/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 172/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 173/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0156 - mean_absolute_error: 0.0957 - val_loss: 0.0154 - val_mean_absolute_error: 0.0930\n",
      "Epoch 174/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 175/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0958 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 176/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0933\n",
      "Epoch 177/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0159 - val_mean_absolute_error: 0.0936\n",
      "Epoch 178/500\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.0211 - mean_absolute_error: 0.101 - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 179/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0156 - mean_absolute_error: 0.0951 - val_loss: 0.0157 - val_mean_absolute_error: 0.0933\n",
      "Epoch 180/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0958 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 181/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 182/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 183/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 184/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0955 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 185/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0157 - mean_absolute_error: 0.0957 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n",
      "Epoch 186/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0157 - mean_absolute_error: 0.0956 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n",
      "Epoch 187/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0157 - mean_absolute_error: 0.0964 - val_loss: 0.0155 - val_mean_absolute_error: 0.0932\n",
      "Epoch 188/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0932\n",
      "Epoch 189/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0158 - val_mean_absolute_error: 0.0935\n",
      "Epoch 190/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 191/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 193/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 194/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0154 - val_mean_absolute_error: 0.0930\n",
      "Epoch 195/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 196/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0153 - val_mean_absolute_error: 0.0930\n",
      "Epoch 197/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0933\n",
      "Epoch 198/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0158 - mean_absolute_error: 0.0961 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 199/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 200/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 201/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 202/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0930\n",
      "Epoch 203/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0152 - val_mean_absolute_error: 0.0933\n",
      "Epoch 204/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 205/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0156 - mean_absolute_error: 0.0957 - val_loss: 0.0164 - val_mean_absolute_error: 0.0948\n",
      "Epoch 206/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0156 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 207/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0156 - mean_absolute_error: 0.0956 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 208/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 209/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 210/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0158 - val_mean_absolute_error: 0.0935\n",
      "Epoch 211/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 212/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0162 - val_mean_absolute_error: 0.0943\n",
      "Epoch 213/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0155 - mean_absolute_error: 0.0956 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 214/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0158 - mean_absolute_error: 0.0955 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 215/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 216/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0156 - mean_absolute_error: 0.0952 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 217/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0158 - val_mean_absolute_error: 0.0933\n",
      "Epoch 218/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0931\n",
      "Epoch 219/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 220/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 221/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0932\n",
      "Epoch 222/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 223/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0160 - val_mean_absolute_error: 0.0938\n",
      "Epoch 224/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 225/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 226/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 227/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0152 - val_mean_absolute_error: 0.0929\n",
      "Epoch 228/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0156 - mean_absolute_error: 0.0951 - val_loss: 0.0152 - val_mean_absolute_error: 0.0937\n",
      "Epoch 229/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0156 - mean_absolute_error: 0.0958 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 230/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 231/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 232/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0153 - val_mean_absolute_error: 0.0930\n",
      "Epoch 233/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 234/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 235/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0947 - val_loss: 0.0153 - val_mean_absolute_error: 0.0930\n",
      "Epoch 236/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0156 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 237/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 238/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0929\n",
      "Epoch 239/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0155 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0157 - mean_absolute_error: 0.0959 - val_loss: 0.0153 - val_mean_absolute_error: 0.0934\n",
      "Epoch 241/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0156 - mean_absolute_error: 0.0961 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 242/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 243/500\n",
      "1406/1406 [==============================] - 0s 31us/step - loss: 0.0156 - mean_absolute_error: 0.0959 - val_loss: 0.0163 - val_mean_absolute_error: 0.0944\n",
      "Epoch 244/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0948 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 245/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 246/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 247/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 248/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 249/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 250/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 251/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 252/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 253/500\n",
      "1406/1406 [==============================] - 0s 31us/step - loss: 0.0156 - mean_absolute_error: 0.0958 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 254/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 255/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0161 - val_mean_absolute_error: 0.0937\n",
      "Epoch 256/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0928\n",
      "Epoch 257/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0160 - val_mean_absolute_error: 0.0935\n",
      "Epoch 258/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0156 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 259/500\n",
      "1406/1406 [==============================] - 0s 30us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 260/500\n",
      "1406/1406 [==============================] - 0s 30us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 261/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 262/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 263/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0161 - val_mean_absolute_error: 0.0938\n",
      "Epoch 264/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 265/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 266/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0157 - val_mean_absolute_error: 0.0932\n",
      "Epoch 267/500\n",
      "1406/1406 [==============================] - 0s 56us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0932\n",
      "Epoch 268/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 269/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 270/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0930\n",
      "Epoch 271/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 272/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 273/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0957 - val_loss: 0.0156 - val_mean_absolute_error: 0.0932\n",
      "Epoch 274/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 275/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0160 - val_mean_absolute_error: 0.0936\n",
      "Epoch 276/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0155 - mean_absolute_error: 0.0956 - val_loss: 0.0164 - val_mean_absolute_error: 0.0947\n",
      "Epoch 277/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 278/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0165 - val_mean_absolute_error: 0.0948\n",
      "Epoch 279/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0156 - mean_absolute_error: 0.0950 - val_loss: 0.0166 - val_mean_absolute_error: 0.0950\n",
      "Epoch 280/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0151 - val_mean_absolute_error: 0.0935\n",
      "Epoch 281/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0952 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 282/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 283/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 284/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0160 - val_mean_absolute_error: 0.0936\n",
      "Epoch 285/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 286/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0161 - val_mean_absolute_error: 0.0939\n",
      "Epoch 287/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 288/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 289/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0155 - mean_absolute_error: 0.0948 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 290/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 291/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0929\n",
      "Epoch 292/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 293/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0161 - val_mean_absolute_error: 0.0937\n",
      "Epoch 294/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0947 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 295/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0155 - mean_absolute_error: 0.0959 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 296/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 297/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 298/500\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.0219 - mean_absolute_error: 0.115 - 0s 37us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 299/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 300/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 301/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 302/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 303/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 304/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0155 - mean_absolute_error: 0.0957 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 305/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 306/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 307/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 308/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0162 - val_mean_absolute_error: 0.0941\n",
      "Epoch 309/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0151 - val_mean_absolute_error: 0.0929\n",
      "Epoch 310/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0158 - val_mean_absolute_error: 0.0933\n",
      "Epoch 311/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0152 - val_mean_absolute_error: 0.0931\n",
      "Epoch 312/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 313/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 314/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0154 - val_mean_absolute_error: 0.0930\n",
      "Epoch 315/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 316/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 317/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 318/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 319/500\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 320/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 321/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0164 - val_mean_absolute_error: 0.0946\n",
      "Epoch 322/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 323/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0157 - mean_absolute_error: 0.0964 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 324/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0155 - val_mean_absolute_error: 0.0928\n",
      "Epoch 325/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 326/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 327/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 328/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 329/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 330/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 331/500\n",
      "1406/1406 [==============================] - 0s 39us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 332/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0958 - val_loss: 0.0158 - val_mean_absolute_error: 0.0935\n",
      "Epoch 333/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 334/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0159 - val_mean_absolute_error: 0.0934\n",
      "Epoch 335/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0158 - val_mean_absolute_error: 0.0933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0154 - val_mean_absolute_error: 0.0929\n",
      "Epoch 337/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 338/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 339/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 340/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 341/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0151 - val_mean_absolute_error: 0.0929\n",
      "Epoch 342/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0151 - val_mean_absolute_error: 0.0929\n",
      "Epoch 343/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 344/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 345/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 346/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0956 - val_loss: 0.0164 - val_mean_absolute_error: 0.0946\n",
      "Epoch 347/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0160 - val_mean_absolute_error: 0.0936\n",
      "Epoch 348/500\n",
      "1406/1406 [==============================] - 0s 36us/step - loss: 0.0156 - mean_absolute_error: 0.0952 - val_loss: 0.0150 - val_mean_absolute_error: 0.0935\n",
      "Epoch 349/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 350/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 351/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 352/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 353/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 354/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 355/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 356/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 357/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 358/500\n",
      "1406/1406 [==============================] - 0s 38us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 359/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 360/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0153 - mean_absolute_error: 0.0947 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 361/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0154 - mean_absolute_error: 0.0955 - val_loss: 0.0152 - val_mean_absolute_error: 0.0928\n",
      "Epoch 362/500\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.0153 - mean_absolute_error: 0.0945 - val_loss: 0.0150 - val_mean_absolute_error: 0.0933\n",
      "Epoch 363/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0156 - mean_absolute_error: 0.0957 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 364/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0153 - mean_absolute_error: 0.0945 - val_loss: 0.0150 - val_mean_absolute_error: 0.0936\n",
      "Epoch 365/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 366/500\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0150 - val_mean_absolute_error: 0.0934\n",
      "Epoch 367/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929\n",
      "Epoch 368/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 369/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0937\n",
      "Epoch 370/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0958 - val_loss: 0.0150 - val_mean_absolute_error: 0.0933\n",
      "Epoch 371/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 372/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 373/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0156 - val_mean_absolute_error: 0.0931\n",
      "Epoch 374/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 375/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0155 - mean_absolute_error: 0.0950 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 376/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0158 - val_mean_absolute_error: 0.0933\n",
      "Epoch 377/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 378/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 379/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 380/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 381/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0158 - val_mean_absolute_error: 0.0934\n",
      "Epoch 382/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 383/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 385/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 386/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 387/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 388/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 389/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 390/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 391/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 392/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0153 - mean_absolute_error: 0.0947 - val_loss: 0.0150 - val_mean_absolute_error: 0.0931\n",
      "Epoch 393/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0956 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 394/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 395/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 396/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 397/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0157 - val_mean_absolute_error: 0.0930\n",
      "Epoch 398/500\n",
      "1406/1406 [==============================] - 0s 34us/step - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 399/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 400/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 401/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0153 - mean_absolute_error: 0.0951 - val_loss: 0.0166 - val_mean_absolute_error: 0.0952\n",
      "Epoch 402/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0154 - val_mean_absolute_error: 0.0927\n",
      "Epoch 403/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0956 - val_loss: 0.0160 - val_mean_absolute_error: 0.0937\n",
      "Epoch 404/500\n",
      "1406/1406 [==============================] - 0s 32us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 405/500\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 406/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 407/500\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 408/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 409/500\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 410/500\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 411/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0159 - val_mean_absolute_error: 0.0933\n",
      "Epoch 412/500\n",
      "1406/1406 [==============================] - 0s 58us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 413/500\n",
      "1406/1406 [==============================] - 0s 58us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 414/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0947 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 415/500\n",
      "1406/1406 [==============================] - 0s 61us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 416/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 417/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0155 - val_mean_absolute_error: 0.0930\n",
      "Epoch 418/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0947 - val_loss: 0.0154 - val_mean_absolute_error: 0.0927\n",
      "Epoch 419/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0947 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 420/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0152 - mean_absolute_error: 0.0945 - val_loss: 0.0170 - val_mean_absolute_error: 0.0960\n",
      "Epoch 421/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 422/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0929\n",
      "Epoch 423/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0150 - val_mean_absolute_error: 0.0928\n",
      "Epoch 424/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0155 - mean_absolute_error: 0.0954 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 425/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 426/500\n",
      "1406/1406 [==============================] - 0s 37us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0150 - val_mean_absolute_error: 0.0929\n",
      "Epoch 427/500\n",
      "1406/1406 [==============================] - 0s 35us/step - loss: 0.0153 - mean_absolute_error: 0.0943 - val_loss: 0.0150 - val_mean_absolute_error: 0.0934\n",
      "Epoch 428/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 429/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 430/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 431/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 433/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0163 - val_mean_absolute_error: 0.0945\n",
      "Epoch 434/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0155 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 435/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0154 - mean_absolute_error: 0.0956 - val_loss: 0.0166 - val_mean_absolute_error: 0.0951\n",
      "Epoch 436/500\n",
      "1406/1406 [==============================] - 0s 33us/step - loss: 0.0155 - mean_absolute_error: 0.0951 - val_loss: 0.0155 - val_mean_absolute_error: 0.0929\n",
      "Epoch 437/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 438/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0955 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 439/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 440/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0150 - val_mean_absolute_error: 0.0925\n",
      "Epoch 441/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0153 - mean_absolute_error: 0.0945 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 442/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0151 - val_mean_absolute_error: 0.0925\n",
      "Epoch 443/500\n",
      "1406/1406 [==============================] - 0s 40us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0151 - val_mean_absolute_error: 0.0925\n",
      "Epoch 444/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 445/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0157 - val_mean_absolute_error: 0.0930\n",
      "Epoch 446/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 447/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0154 - val_mean_absolute_error: 0.0927\n",
      "Epoch 448/500\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.0153 - mean_absolute_error: 0.0947 - val_loss: 0.0157 - val_mean_absolute_error: 0.0930\n",
      "Epoch 449/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 450/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 451/500\n",
      "1406/1406 [==============================] - 0s 42us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 452/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 453/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0155 - mean_absolute_error: 0.0955 - val_loss: 0.0150 - val_mean_absolute_error: 0.0927\n",
      "Epoch 454/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0952 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 455/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 456/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0151 - val_mean_absolute_error: 0.0928\n",
      "Epoch 457/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0955 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 458/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 459/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931\n",
      "Epoch 460/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0153 - mean_absolute_error: 0.0946 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 461/500\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.0154 - mean_absolute_error: 0.0955 - val_loss: 0.0151 - val_mean_absolute_error: 0.0926\n",
      "Epoch 462/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0153 - mean_absolute_error: 0.0955 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 463/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0945 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 464/500\n",
      "1406/1406 [==============================] - 0s 61us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 465/500\n",
      "1406/1406 [==============================] - 0s 61us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 466/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0155 - val_mean_absolute_error: 0.0928\n",
      "Epoch 467/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0156 - val_mean_absolute_error: 0.0929\n",
      "Epoch 468/500\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0154 - val_mean_absolute_error: 0.0927\n",
      "Epoch 469/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0150 - val_mean_absolute_error: 0.0930\n",
      "Epoch 470/500\n",
      "1406/1406 [==============================] - 0s 61us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 471/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0161 - val_mean_absolute_error: 0.0940\n",
      "Epoch 472/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0153 - val_mean_absolute_error: 0.0926\n",
      "Epoch 473/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0153 - mean_absolute_error: 0.0946 - val_loss: 0.0150 - val_mean_absolute_error: 0.0927\n",
      "Epoch 474/500\n",
      "1406/1406 [==============================] - 0s 51us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0157 - val_mean_absolute_error: 0.0931\n",
      "Epoch 475/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0153 - mean_absolute_error: 0.0943 - val_loss: 0.0150 - val_mean_absolute_error: 0.0933\n",
      "Epoch 476/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0953 - val_loss: 0.0153 - val_mean_absolute_error: 0.0926\n",
      "Epoch 477/500\n",
      "1406/1406 [==============================] - 0s 45us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 478/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 479/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0954 - val_loss: 0.0163 - val_mean_absolute_error: 0.0944\n",
      "Epoch 481/500\n",
      "1406/1406 [==============================] - 0s 46us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0159 - val_mean_absolute_error: 0.0935\n",
      "Epoch 482/500\n",
      "1406/1406 [==============================] - 0s 58us/step - loss: 0.0153 - mean_absolute_error: 0.0946 - val_loss: 0.0152 - val_mean_absolute_error: 0.0925\n",
      "Epoch 483/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0153 - mean_absolute_error: 0.0945 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 484/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0150 - val_mean_absolute_error: 0.0933\n",
      "Epoch 485/500\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0153 - val_mean_absolute_error: 0.0928\n",
      "Epoch 486/500\n",
      "1406/1406 [==============================] - 0s 44us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0150 - val_mean_absolute_error: 0.0925\n",
      "Epoch 487/500\n",
      "1406/1406 [==============================] - 0s 41us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0156 - val_mean_absolute_error: 0.0930\n",
      "Epoch 488/500\n",
      "1406/1406 [==============================] - 0s 59us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0154 - val_mean_absolute_error: 0.0928\n",
      "Epoch 489/500\n",
      "1406/1406 [==============================] - 0s 47us/step - loss: 0.0154 - mean_absolute_error: 0.0946 - val_loss: 0.0150 - val_mean_absolute_error: 0.0928\n",
      "Epoch 490/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0153 - mean_absolute_error: 0.0947 - val_loss: 0.0150 - val_mean_absolute_error: 0.0941\n",
      "Epoch 491/500\n",
      "1406/1406 [==============================] - 0s 54us/step - loss: 0.0155 - mean_absolute_error: 0.0959 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 492/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0925\n",
      "Epoch 493/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0154 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0926\n",
      "Epoch 494/500\n",
      "1406/1406 [==============================] - 0s 43us/step - loss: 0.0154 - mean_absolute_error: 0.0948 - val_loss: 0.0158 - val_mean_absolute_error: 0.0932\n",
      "Epoch 495/500\n",
      "1406/1406 [==============================] - 0s 48us/step - loss: 0.0153 - mean_absolute_error: 0.0948 - val_loss: 0.0152 - val_mean_absolute_error: 0.0927\n",
      "Epoch 496/500\n",
      "1406/1406 [==============================] - 0s 52us/step - loss: 0.0153 - mean_absolute_error: 0.0950 - val_loss: 0.0155 - val_mean_absolute_error: 0.0928\n",
      "Epoch 497/500\n",
      "1406/1406 [==============================] - 0s 53us/step - loss: 0.0153 - mean_absolute_error: 0.0946 - val_loss: 0.0150 - val_mean_absolute_error: 0.0927\n",
      "Epoch 498/500\n",
      "1406/1406 [==============================] - 0s 49us/step - loss: 0.0153 - mean_absolute_error: 0.0949 - val_loss: 0.0152 - val_mean_absolute_error: 0.0926\n",
      "Epoch 499/500\n",
      "1406/1406 [==============================] - 0s 50us/step - loss: 0.0154 - mean_absolute_error: 0.0949 - val_loss: 0.0153 - val_mean_absolute_error: 0.0926\n",
      "Epoch 500/500\n",
      "1406/1406 [==============================] - 0s 55us/step - loss: 0.0154 - mean_absolute_error: 0.0950 - val_loss: 0.0159 - val_mean_absolute_error: 0.0936\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "#K.clear_session()\n",
    "#keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=100)\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(5, activation='relu', kernel_initializer='normal',input_shape=(10,)))\n",
    "model.add(layers.Dense(1,kernel_initializer='normal'))\n",
    "model.compile(optimizer=\"adam\", metrics=['mae'], loss='mse')\n",
    "history=model.fit(X_train,y_train,epochs=500, batch_size=25,validation_split=0.2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Hidden Layer Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1406 samples, validate on 352 samples\n",
      "Epoch 1/200\n",
      "1406/1406 [==============================] - 1s 714us/step - loss: 0.2481 - mean_absolute_error: 0.4506 - val_loss: 0.1249 - val_mean_absolute_error: 0.2973\n",
      "Epoch 2/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0590 - mean_absolute_error: 0.1943 - val_loss: 0.0375 - val_mean_absolute_error: 0.1602\n",
      "Epoch 3/200\n",
      "1406/1406 [==============================] - 0s 63us/step - loss: 0.0343 - mean_absolute_error: 0.1557 - val_loss: 0.0317 - val_mean_absolute_error: 0.1455\n",
      "Epoch 4/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0286 - mean_absolute_error: 0.1413 - val_loss: 0.0260 - val_mean_absolute_error: 0.1302\n",
      "Epoch 5/200\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.0234 - mean_absolute_error: 0.1258 - val_loss: 0.0222 - val_mean_absolute_error: 0.1174\n",
      "Epoch 6/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0195 - mean_absolute_error: 0.1119 - val_loss: 0.0189 - val_mean_absolute_error: 0.1054\n",
      "Epoch 7/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0171 - mean_absolute_error: 0.1030 - val_loss: 0.0173 - val_mean_absolute_error: 0.0992\n",
      "Epoch 8/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0160 - mean_absolute_error: 0.0980 - val_loss: 0.0157 - val_mean_absolute_error: 0.0943\n",
      "Epoch 9/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0155 - mean_absolute_error: 0.0961 - val_loss: 0.0151 - val_mean_absolute_error: 0.0927\n",
      "Epoch 10/200\n",
      "1406/1406 [==============================] - 0s 74us/step - loss: 0.0154 - mean_absolute_error: 0.0957 - val_loss: 0.0150 - val_mean_absolute_error: 0.0922\n",
      "Epoch 11/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0152 - mean_absolute_error: 0.0951 - val_loss: 0.0153 - val_mean_absolute_error: 0.0927\n",
      "Epoch 12/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0151 - mean_absolute_error: 0.0947 - val_loss: 0.0149 - val_mean_absolute_error: 0.0922\n",
      "Epoch 13/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0151 - mean_absolute_error: 0.0944 - val_loss: 0.0147 - val_mean_absolute_error: 0.0923\n",
      "Epoch 14/200\n",
      "1406/1406 [==============================] - 0s 67us/step - loss: 0.0150 - mean_absolute_error: 0.0948 - val_loss: 0.0164 - val_mean_absolute_error: 0.0952\n",
      "Epoch 15/200\n",
      "1406/1406 [==============================] - 0s 73us/step - loss: 0.0151 - mean_absolute_error: 0.0944 - val_loss: 0.0148 - val_mean_absolute_error: 0.0915\n",
      "Epoch 16/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0149 - mean_absolute_error: 0.0938 - val_loss: 0.0150 - val_mean_absolute_error: 0.0916\n",
      "Epoch 17/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0148 - mean_absolute_error: 0.0935 - val_loss: 0.0150 - val_mean_absolute_error: 0.0915\n",
      "Epoch 18/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0148 - mean_absolute_error: 0.0937 - val_loss: 0.0152 - val_mean_absolute_error: 0.0919\n",
      "Epoch 19/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0148 - mean_absolute_error: 0.0932 - val_loss: 0.0144 - val_mean_absolute_error: 0.0908\n",
      "Epoch 20/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0148 - mean_absolute_error: 0.0933 - val_loss: 0.0147 - val_mean_absolute_error: 0.0908\n",
      "Epoch 21/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0147 - mean_absolute_error: 0.0930 - val_loss: 0.0143 - val_mean_absolute_error: 0.0910\n",
      "Epoch 22/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0147 - mean_absolute_error: 0.0933 - val_loss: 0.0150 - val_mean_absolute_error: 0.0911\n",
      "Epoch 23/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0148 - mean_absolute_error: 0.0932 - val_loss: 0.0149 - val_mean_absolute_error: 0.0909\n",
      "Epoch 24/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0146 - mean_absolute_error: 0.0927 - val_loss: 0.0141 - val_mean_absolute_error: 0.0910\n",
      "Epoch 25/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0147 - mean_absolute_error: 0.0929 - val_loss: 0.0146 - val_mean_absolute_error: 0.0903\n",
      "Epoch 26/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0146 - mean_absolute_error: 0.0928 - val_loss: 0.0143 - val_mean_absolute_error: 0.0902\n",
      "Epoch 27/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0146 - mean_absolute_error: 0.0926 - val_loss: 0.0142 - val_mean_absolute_error: 0.0902\n",
      "Epoch 28/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0147 - mean_absolute_error: 0.0930 - val_loss: 0.0148 - val_mean_absolute_error: 0.0907\n",
      "Epoch 29/200\n",
      "1406/1406 [==============================] - 0s 95us/step - loss: 0.0145 - mean_absolute_error: 0.0920 - val_loss: 0.0144 - val_mean_absolute_error: 0.0900\n",
      "Epoch 30/200\n",
      "1406/1406 [==============================] - 0s 87us/step - loss: 0.0144 - mean_absolute_error: 0.0916 - val_loss: 0.0141 - val_mean_absolute_error: 0.0913\n",
      "Epoch 31/200\n",
      "1406/1406 [==============================] - 0s 92us/step - loss: 0.0145 - mean_absolute_error: 0.0925 - val_loss: 0.0142 - val_mean_absolute_error: 0.0898\n",
      "Epoch 32/200\n",
      "1406/1406 [==============================] - 0s 85us/step - loss: 0.0146 - mean_absolute_error: 0.0918 - val_loss: 0.0144 - val_mean_absolute_error: 0.0899\n",
      "Epoch 33/200\n",
      "1406/1406 [==============================] - 0s 74us/step - loss: 0.0145 - mean_absolute_error: 0.0922 - val_loss: 0.0140 - val_mean_absolute_error: 0.0899\n",
      "Epoch 34/200\n",
      "1406/1406 [==============================] - 0s 78us/step - loss: 0.0145 - mean_absolute_error: 0.0929 - val_loss: 0.0140 - val_mean_absolute_error: 0.0899\n",
      "Epoch 35/200\n",
      "1406/1406 [==============================] - 0s 92us/step - loss: 0.0144 - mean_absolute_error: 0.0918 - val_loss: 0.0143 - val_mean_absolute_error: 0.0898\n",
      "Epoch 36/200\n",
      "1406/1406 [==============================] - 0s 103us/step - loss: 0.0146 - mean_absolute_error: 0.0921 - val_loss: 0.0139 - val_mean_absolute_error: 0.0901\n",
      "Epoch 37/200\n",
      "1406/1406 [==============================] - 0s 100us/step - loss: 0.0144 - mean_absolute_error: 0.0920 - val_loss: 0.0140 - val_mean_absolute_error: 0.0896\n",
      "Epoch 38/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0144 - mean_absolute_error: 0.0915 - val_loss: 0.0139 - val_mean_absolute_error: 0.0911\n",
      "Epoch 39/200\n",
      "1406/1406 [==============================] - 0s 94us/step - loss: 0.0144 - mean_absolute_error: 0.0922 - val_loss: 0.0152 - val_mean_absolute_error: 0.0914\n",
      "Epoch 40/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0144 - mean_absolute_error: 0.0918 - val_loss: 0.0144 - val_mean_absolute_error: 0.0895\n",
      "Epoch 41/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0143 - mean_absolute_error: 0.0912 - val_loss: 0.0138 - val_mean_absolute_error: 0.0908\n",
      "Epoch 42/200\n",
      "1406/1406 [==============================] - 0s 88us/step - loss: 0.0144 - mean_absolute_error: 0.0918 - val_loss: 0.0138 - val_mean_absolute_error: 0.0900\n",
      "Epoch 43/200\n",
      "1406/1406 [==============================] - 0s 74us/step - loss: 0.0143 - mean_absolute_error: 0.0916 - val_loss: 0.0141 - val_mean_absolute_error: 0.0894\n",
      "Epoch 44/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0143 - mean_absolute_error: 0.0917 - val_loss: 0.0140 - val_mean_absolute_error: 0.0893\n",
      "Epoch 45/200\n",
      "1406/1406 [==============================] - 0s 103us/step - loss: 0.0142 - mean_absolute_error: 0.0913 - val_loss: 0.0138 - val_mean_absolute_error: 0.0896\n",
      "Epoch 46/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0142 - mean_absolute_error: 0.0912 - val_loss: 0.0140 - val_mean_absolute_error: 0.0893\n",
      "Epoch 47/200\n",
      "1406/1406 [==============================] - 0s 81us/step - loss: 0.0142 - mean_absolute_error: 0.0912 - val_loss: 0.0143 - val_mean_absolute_error: 0.0895\n",
      "Epoch 48/200\n",
      "1406/1406 [==============================] - 0s 64us/step - loss: 0.0143 - mean_absolute_error: 0.0912 - val_loss: 0.0138 - val_mean_absolute_error: 0.0897\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 70us/step - loss: 0.0142 - mean_absolute_error: 0.0915 - val_loss: 0.0140 - val_mean_absolute_error: 0.0894\n",
      "Epoch 50/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0142 - mean_absolute_error: 0.0913 - val_loss: 0.0144 - val_mean_absolute_error: 0.0896\n",
      "Epoch 51/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0142 - mean_absolute_error: 0.0909 - val_loss: 0.0143 - val_mean_absolute_error: 0.0894\n",
      "Epoch 52/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0142 - mean_absolute_error: 0.0910 - val_loss: 0.0139 - val_mean_absolute_error: 0.0893\n",
      "Epoch 53/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0141 - mean_absolute_error: 0.0906 - val_loss: 0.0137 - val_mean_absolute_error: 0.0906\n",
      "Epoch 54/200\n",
      "1406/1406 [==============================] - 0s 60us/step - loss: 0.0142 - mean_absolute_error: 0.0915 - val_loss: 0.0139 - val_mean_absolute_error: 0.0892\n",
      "Epoch 55/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0141 - mean_absolute_error: 0.0912 - val_loss: 0.0138 - val_mean_absolute_error: 0.0895\n",
      "Epoch 56/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0144 - mean_absolute_error: 0.0922 - val_loss: 0.0138 - val_mean_absolute_error: 0.0894\n",
      "Epoch 57/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0142 - mean_absolute_error: 0.0911 - val_loss: 0.0142 - val_mean_absolute_error: 0.0892\n",
      "Epoch 58/200\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.0142 - mean_absolute_error: 0.0909 - val_loss: 0.0136 - val_mean_absolute_error: 0.0902\n",
      "Epoch 59/200\n",
      "1406/1406 [==============================] - 0s 61us/step - loss: 0.0141 - mean_absolute_error: 0.0907 - val_loss: 0.0141 - val_mean_absolute_error: 0.0893\n",
      "Epoch 60/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0141 - mean_absolute_error: 0.0910 - val_loss: 0.0140 - val_mean_absolute_error: 0.0892\n",
      "Epoch 61/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0142 - mean_absolute_error: 0.0910 - val_loss: 0.0138 - val_mean_absolute_error: 0.0892\n",
      "Epoch 62/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0141 - mean_absolute_error: 0.0908 - val_loss: 0.0151 - val_mean_absolute_error: 0.0911\n",
      "Epoch 63/200\n",
      "1406/1406 [==============================] - 0s 91us/step - loss: 0.0140 - mean_absolute_error: 0.0896 - val_loss: 0.0138 - val_mean_absolute_error: 0.0891\n",
      "Epoch 64/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0140 - mean_absolute_error: 0.0905 - val_loss: 0.0137 - val_mean_absolute_error: 0.0892\n",
      "Epoch 65/200\n",
      "1406/1406 [==============================] - 0s 94us/step - loss: 0.0140 - mean_absolute_error: 0.0904 - val_loss: 0.0136 - val_mean_absolute_error: 0.0898\n",
      "Epoch 66/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0140 - mean_absolute_error: 0.0908 - val_loss: 0.0140 - val_mean_absolute_error: 0.0892\n",
      "Epoch 67/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0140 - mean_absolute_error: 0.0903 - val_loss: 0.0136 - val_mean_absolute_error: 0.0904\n",
      "Epoch 68/200\n",
      "1406/1406 [==============================] - 0s 94us/step - loss: 0.0141 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0895\n",
      "Epoch 69/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0141 - mean_absolute_error: 0.0911 - val_loss: 0.0142 - val_mean_absolute_error: 0.0894\n",
      "Epoch 70/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0140 - mean_absolute_error: 0.0903 - val_loss: 0.0135 - val_mean_absolute_error: 0.0902\n",
      "Epoch 71/200\n",
      "1406/1406 [==============================] - 0s 88us/step - loss: 0.0140 - mean_absolute_error: 0.0910 - val_loss: 0.0138 - val_mean_absolute_error: 0.0890\n",
      "Epoch 72/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0142 - mean_absolute_error: 0.0913 - val_loss: 0.0135 - val_mean_absolute_error: 0.0892\n",
      "Epoch 73/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0140 - mean_absolute_error: 0.0904 - val_loss: 0.0135 - val_mean_absolute_error: 0.0893\n",
      "Epoch 74/200\n",
      "1406/1406 [==============================] - 0s 103us/step - loss: 0.0140 - mean_absolute_error: 0.0904 - val_loss: 0.0139 - val_mean_absolute_error: 0.0891\n",
      "Epoch 75/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0140 - mean_absolute_error: 0.0905 - val_loss: 0.0139 - val_mean_absolute_error: 0.0892\n",
      "Epoch 76/200\n",
      "1406/1406 [==============================] - 0s 91us/step - loss: 0.0139 - mean_absolute_error: 0.0903 - val_loss: 0.0136 - val_mean_absolute_error: 0.0893\n",
      "Epoch 77/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0139 - mean_absolute_error: 0.0903 - val_loss: 0.0140 - val_mean_absolute_error: 0.0893\n",
      "Epoch 78/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0139 - mean_absolute_error: 0.0897 - val_loss: 0.0137 - val_mean_absolute_error: 0.0890\n",
      "Epoch 79/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0140 - mean_absolute_error: 0.0905 - val_loss: 0.0135 - val_mean_absolute_error: 0.0898\n",
      "Epoch 80/200\n",
      "1406/1406 [==============================] - 0s 70us/step - loss: 0.0140 - mean_absolute_error: 0.0902 - val_loss: 0.0137 - val_mean_absolute_error: 0.0890\n",
      "Epoch 81/200\n",
      "1406/1406 [==============================] - 0s 93us/step - loss: 0.0141 - mean_absolute_error: 0.0905 - val_loss: 0.0138 - val_mean_absolute_error: 0.0890\n",
      "Epoch 82/200\n",
      "1406/1406 [==============================] - 0s 104us/step - loss: 0.0139 - mean_absolute_error: 0.0900 - val_loss: 0.0142 - val_mean_absolute_error: 0.0893\n",
      "Epoch 83/200\n",
      "1406/1406 [==============================] - 0s 97us/step - loss: 0.0139 - mean_absolute_error: 0.0898 - val_loss: 0.0135 - val_mean_absolute_error: 0.0912\n",
      "Epoch 84/200\n",
      "1406/1406 [==============================] - 0s 97us/step - loss: 0.0140 - mean_absolute_error: 0.0906 - val_loss: 0.0138 - val_mean_absolute_error: 0.0890\n",
      "Epoch 85/200\n",
      "1406/1406 [==============================] - 0s 90us/step - loss: 0.0139 - mean_absolute_error: 0.0897 - val_loss: 0.0136 - val_mean_absolute_error: 0.0893\n",
      "Epoch 86/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0139 - mean_absolute_error: 0.0907 - val_loss: 0.0136 - val_mean_absolute_error: 0.0891\n",
      "Epoch 87/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0139 - mean_absolute_error: 0.0898 - val_loss: 0.0135 - val_mean_absolute_error: 0.0892\n",
      "Epoch 88/200\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.089 - 0s 76us/step - loss: 0.0140 - mean_absolute_error: 0.0901 - val_loss: 0.0138 - val_mean_absolute_error: 0.0892\n",
      "Epoch 89/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0139 - mean_absolute_error: 0.0902 - val_loss: 0.0142 - val_mean_absolute_error: 0.0895\n",
      "Epoch 90/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0139 - mean_absolute_error: 0.0902 - val_loss: 0.0140 - val_mean_absolute_error: 0.0892\n",
      "Epoch 91/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0140 - mean_absolute_error: 0.0901 - val_loss: 0.0135 - val_mean_absolute_error: 0.0901\n",
      "Epoch 92/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0139 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0891\n",
      "Epoch 93/200\n",
      "1406/1406 [==============================] - 0s 81us/step - loss: 0.0138 - mean_absolute_error: 0.0898 - val_loss: 0.0142 - val_mean_absolute_error: 0.0897\n",
      "Epoch 94/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0139 - mean_absolute_error: 0.0900 - val_loss: 0.0138 - val_mean_absolute_error: 0.0893\n",
      "Epoch 95/200\n",
      "1406/1406 [==============================] - 0s 81us/step - loss: 0.0139 - mean_absolute_error: 0.0899 - val_loss: 0.0134 - val_mean_absolute_error: 0.0898\n",
      "Epoch 96/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0897 - val_loss: 0.0135 - val_mean_absolute_error: 0.0905\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 88us/step - loss: 0.0139 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0893\n",
      "Epoch 98/200\n",
      "1406/1406 [==============================] - 0s 90us/step - loss: 0.0139 - mean_absolute_error: 0.0902 - val_loss: 0.0139 - val_mean_absolute_error: 0.0893\n",
      "Epoch 99/200\n",
      "1406/1406 [==============================] - 0s 85us/step - loss: 0.0139 - mean_absolute_error: 0.0905 - val_loss: 0.0139 - val_mean_absolute_error: 0.0893\n",
      "Epoch 100/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0139 - mean_absolute_error: 0.0899 - val_loss: 0.0139 - val_mean_absolute_error: 0.0894\n",
      "Epoch 101/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0139 - mean_absolute_error: 0.0903 - val_loss: 0.0143 - val_mean_absolute_error: 0.0899\n",
      "Epoch 102/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0139 - mean_absolute_error: 0.0900 - val_loss: 0.0138 - val_mean_absolute_error: 0.0891\n",
      "Epoch 103/200\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0143 - val_mean_absolute_error: 0.0900\n",
      "Epoch 104/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0139 - mean_absolute_error: 0.0907 - val_loss: 0.0137 - val_mean_absolute_error: 0.0894\n",
      "Epoch 105/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0138 - mean_absolute_error: 0.0894 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 106/200\n",
      "1406/1406 [==============================] - 0s 89us/step - loss: 0.0139 - mean_absolute_error: 0.0902 - val_loss: 0.0139 - val_mean_absolute_error: 0.0896\n",
      "Epoch 107/200\n",
      "1406/1406 [==============================] - 0s 85us/step - loss: 0.0139 - mean_absolute_error: 0.0905 - val_loss: 0.0140 - val_mean_absolute_error: 0.0898\n",
      "Epoch 108/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0138 - mean_absolute_error: 0.0898 - val_loss: 0.0136 - val_mean_absolute_error: 0.0893\n",
      "Epoch 109/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0904 - val_loss: 0.0150 - val_mean_absolute_error: 0.0915\n",
      "Epoch 110/200\n",
      "1406/1406 [==============================] - 0s 74us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0139 - val_mean_absolute_error: 0.0896\n",
      "Epoch 111/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0138 - mean_absolute_error: 0.0896 - val_loss: 0.0135 - val_mean_absolute_error: 0.0902\n",
      "Epoch 112/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0139 - mean_absolute_error: 0.0907 - val_loss: 0.0149 - val_mean_absolute_error: 0.0914\n",
      "Epoch 113/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0140 - mean_absolute_error: 0.0905 - val_loss: 0.0138 - val_mean_absolute_error: 0.0894\n",
      "Epoch 114/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0134 - val_mean_absolute_error: 0.0904\n",
      "Epoch 115/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0139 - mean_absolute_error: 0.0902 - val_loss: 0.0135 - val_mean_absolute_error: 0.0904\n",
      "Epoch 116/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0135 - val_mean_absolute_error: 0.0900\n",
      "Epoch 117/200\n",
      "1406/1406 [==============================] - 0s 87us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 118/200\n",
      "1406/1406 [==============================] - 0s 70us/step - loss: 0.0139 - mean_absolute_error: 0.0906 - val_loss: 0.0139 - val_mean_absolute_error: 0.0896\n",
      "Epoch 119/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0138 - mean_absolute_error: 0.0897 - val_loss: 0.0134 - val_mean_absolute_error: 0.0901\n",
      "Epoch 120/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0138 - mean_absolute_error: 0.0901 - val_loss: 0.0134 - val_mean_absolute_error: 0.0905\n",
      "Epoch 121/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0140 - mean_absolute_error: 0.0903 - val_loss: 0.0134 - val_mean_absolute_error: 0.0904\n",
      "Epoch 122/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 123/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 124/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0905 - val_loss: 0.0142 - val_mean_absolute_error: 0.0900\n",
      "Epoch 125/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0895 - val_loss: 0.0139 - val_mean_absolute_error: 0.0899\n",
      "Epoch 126/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0137 - mean_absolute_error: 0.0903 - val_loss: 0.0140 - val_mean_absolute_error: 0.0899\n",
      "Epoch 127/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0901 - val_loss: 0.0139 - val_mean_absolute_error: 0.0898\n",
      "Epoch 128/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0136 - val_mean_absolute_error: 0.0899\n",
      "Epoch 129/200\n",
      "1406/1406 [==============================] - 0s 89us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 130/200\n",
      "1406/1406 [==============================] - 0s 68us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0137 - val_mean_absolute_error: 0.0897\n",
      "Epoch 131/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0137 - mean_absolute_error: 0.0900 - val_loss: 0.0141 - val_mean_absolute_error: 0.0900\n",
      "Epoch 132/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0139 - val_mean_absolute_error: 0.0899\n",
      "Epoch 133/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0137 - mean_absolute_error: 0.0894 - val_loss: 0.0138 - val_mean_absolute_error: 0.0896\n",
      "Epoch 134/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0137 - val_mean_absolute_error: 0.0895\n",
      "Epoch 135/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0135 - val_mean_absolute_error: 0.0899\n",
      "Epoch 136/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0135 - val_mean_absolute_error: 0.0902\n",
      "Epoch 137/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0138 - mean_absolute_error: 0.0902 - val_loss: 0.0135 - val_mean_absolute_error: 0.0901\n",
      "Epoch 138/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0135 - val_mean_absolute_error: 0.0902\n",
      "Epoch 139/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0135 - val_mean_absolute_error: 0.0905\n",
      "Epoch 140/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0138 - mean_absolute_error: 0.0902 - val_loss: 0.0139 - val_mean_absolute_error: 0.0898\n",
      "Epoch 141/200\n",
      "1406/1406 [==============================] - 0s 77us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0135 - val_mean_absolute_error: 0.0899\n",
      "Epoch 142/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0135 - val_mean_absolute_error: 0.0908\n",
      "Epoch 143/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 144/200\n",
      "1406/1406 [==============================] - 0s 78us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0134 - val_mean_absolute_error: 0.0915\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 73us/step - loss: 0.0138 - mean_absolute_error: 0.0902 - val_loss: 0.0138 - val_mean_absolute_error: 0.0897\n",
      "Epoch 146/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0137 - mean_absolute_error: 0.0900 - val_loss: 0.0134 - val_mean_absolute_error: 0.0901\n",
      "Epoch 147/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0139 - val_mean_absolute_error: 0.0898\n",
      "Epoch 148/200\n",
      "1406/1406 [==============================] - 0s 81us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0136 - val_mean_absolute_error: 0.0901\n",
      "Epoch 149/200\n",
      "1406/1406 [==============================] - 0s 81us/step - loss: 0.0137 - mean_absolute_error: 0.0899 - val_loss: 0.0137 - val_mean_absolute_error: 0.0897\n",
      "Epoch 150/200\n",
      "1406/1406 [==============================] - 0s 75us/step - loss: 0.0137 - mean_absolute_error: 0.0899 - val_loss: 0.0140 - val_mean_absolute_error: 0.0900\n",
      "Epoch 151/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0138 - mean_absolute_error: 0.0894 - val_loss: 0.0135 - val_mean_absolute_error: 0.0899\n",
      "Epoch 152/200\n",
      "1406/1406 [==============================] - 0s 94us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0134 - val_mean_absolute_error: 0.0901\n",
      "Epoch 153/200\n",
      "1406/1406 [==============================] - 0s 92us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0134 - val_mean_absolute_error: 0.0906\n",
      "Epoch 154/200\n",
      "1406/1406 [==============================] - 0s 91us/step - loss: 0.0137 - mean_absolute_error: 0.0899 - val_loss: 0.0135 - val_mean_absolute_error: 0.0898\n",
      "Epoch 155/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0137 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0898\n",
      "Epoch 156/200\n",
      "1406/1406 [==============================] - 0s 87us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0136 - val_mean_absolute_error: 0.0904\n",
      "Epoch 157/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0137 - mean_absolute_error: 0.0901 - val_loss: 0.0146 - val_mean_absolute_error: 0.0911\n",
      "Epoch 158/200\n",
      "1406/1406 [==============================] - 0s 97us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0134 - val_mean_absolute_error: 0.0909\n",
      "Epoch 159/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0136 - mean_absolute_error: 0.0894 - val_loss: 0.0134 - val_mean_absolute_error: 0.0907\n",
      "Epoch 160/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0137 - mean_absolute_error: 0.0900 - val_loss: 0.0134 - val_mean_absolute_error: 0.0912\n",
      "Epoch 161/200\n",
      "1406/1406 [==============================] - 0s 95us/step - loss: 0.0138 - mean_absolute_error: 0.0906 - val_loss: 0.0140 - val_mean_absolute_error: 0.0901\n",
      "Epoch 162/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0139 - val_mean_absolute_error: 0.0899\n",
      "Epoch 163/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0138 - val_mean_absolute_error: 0.0898\n",
      "Epoch 164/200\n",
      "1406/1406 [==============================] - 0s 92us/step - loss: 0.0138 - mean_absolute_error: 0.0902 - val_loss: 0.0136 - val_mean_absolute_error: 0.0896\n",
      "Epoch 165/200\n",
      "1406/1406 [==============================] - 0s 79us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0134 - val_mean_absolute_error: 0.0901\n",
      "Epoch 166/200\n",
      "1406/1406 [==============================] - 0s 89us/step - loss: 0.0138 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0898\n",
      "Epoch 167/200\n",
      "1406/1406 [==============================] - 0s 85us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0142 - val_mean_absolute_error: 0.0904\n",
      "Epoch 168/200\n",
      "1406/1406 [==============================] - 0s 89us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0138 - val_mean_absolute_error: 0.0898\n",
      "Epoch 169/200\n",
      "1406/1406 [==============================] - 0s 86us/step - loss: 0.0137 - mean_absolute_error: 0.0894 - val_loss: 0.0134 - val_mean_absolute_error: 0.0902\n",
      "Epoch 170/200\n",
      "1406/1406 [==============================] - 0s 69us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0134 - val_mean_absolute_error: 0.0907\n",
      "Epoch 171/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0899 - val_loss: 0.0144 - val_mean_absolute_error: 0.0906\n",
      "Epoch 172/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0134 - val_mean_absolute_error: 0.0912\n",
      "Epoch 173/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0138 - val_mean_absolute_error: 0.0899\n",
      "Epoch 174/200\n",
      "1406/1406 [==============================] - 0s 88us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0135 - val_mean_absolute_error: 0.0900\n",
      "Epoch 175/200\n",
      "1406/1406 [==============================] - 0s 97us/step - loss: 0.0137 - mean_absolute_error: 0.0900 - val_loss: 0.0143 - val_mean_absolute_error: 0.0905\n",
      "Epoch 176/200\n",
      "1406/1406 [==============================] - 0s 90us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0137 - val_mean_absolute_error: 0.0901\n",
      "Epoch 177/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 178/200\n",
      "1406/1406 [==============================] - 0s 108us/step - loss: 0.0138 - mean_absolute_error: 0.0899 - val_loss: 0.0137 - val_mean_absolute_error: 0.0898\n",
      "Epoch 179/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0136 - mean_absolute_error: 0.0893 - val_loss: 0.0134 - val_mean_absolute_error: 0.0911\n",
      "Epoch 180/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0138 - mean_absolute_error: 0.0898 - val_loss: 0.0136 - val_mean_absolute_error: 0.0900\n",
      "Epoch 181/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0138 - mean_absolute_error: 0.0900 - val_loss: 0.0136 - val_mean_absolute_error: 0.0895\n",
      "Epoch 182/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0137 - mean_absolute_error: 0.0902 - val_loss: 0.0138 - val_mean_absolute_error: 0.0898\n",
      "Epoch 183/200\n",
      "1406/1406 [==============================] - 0s 72us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0135 - val_mean_absolute_error: 0.0900\n",
      "Epoch 184/200\n",
      "1406/1406 [==============================] - 0s 76us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0134 - val_mean_absolute_error: 0.0902\n",
      "Epoch 185/200\n",
      "1406/1406 [==============================] - 0s 78us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0134 - val_mean_absolute_error: 0.0905\n",
      "Epoch 186/200\n",
      "1406/1406 [==============================] - 0s 95us/step - loss: 0.0137 - mean_absolute_error: 0.0898 - val_loss: 0.0137 - val_mean_absolute_error: 0.0898\n",
      "Epoch 187/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0134 - val_mean_absolute_error: 0.0900\n",
      "Epoch 188/200\n",
      "1406/1406 [==============================] - 0s 91us/step - loss: 0.0137 - mean_absolute_error: 0.0901 - val_loss: 0.0136 - val_mean_absolute_error: 0.0897\n",
      "Epoch 189/200\n",
      "1406/1406 [==============================] - 0s 83us/step - loss: 0.0136 - mean_absolute_error: 0.0897 - val_loss: 0.0144 - val_mean_absolute_error: 0.0906\n",
      "Epoch 190/200\n",
      "1406/1406 [==============================] - 0s 93us/step - loss: 0.0137 - mean_absolute_error: 0.0903 - val_loss: 0.0138 - val_mean_absolute_error: 0.0899\n",
      "Epoch 191/200\n",
      "1406/1406 [==============================] - 0s 92us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0135 - val_mean_absolute_error: 0.0897\n",
      "Epoch 192/200\n",
      "1406/1406 [==============================] - 0s 82us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0135 - val_mean_absolute_error: 0.0900\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0137 - mean_absolute_error: 0.0897 - val_loss: 0.0141 - val_mean_absolute_error: 0.0902\n",
      "Epoch 194/200\n",
      "1406/1406 [==============================] - 0s 95us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0134 - val_mean_absolute_error: 0.0900\n",
      "Epoch 195/200\n",
      "1406/1406 [==============================] - 0s 69us/step - loss: 0.0137 - mean_absolute_error: 0.0903 - val_loss: 0.0149 - val_mean_absolute_error: 0.0919\n",
      "Epoch 196/200\n",
      "1406/1406 [==============================] - 0s 71us/step - loss: 0.0138 - mean_absolute_error: 0.0901 - val_loss: 0.0137 - val_mean_absolute_error: 0.0898\n",
      "Epoch 197/200\n",
      "1406/1406 [==============================] - 0s 99us/step - loss: 0.0137 - mean_absolute_error: 0.0896 - val_loss: 0.0137 - val_mean_absolute_error: 0.0898\n",
      "Epoch 198/200\n",
      "1406/1406 [==============================] - 0s 84us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0133 - val_mean_absolute_error: 0.0904\n",
      "Epoch 199/200\n",
      "1406/1406 [==============================] - 0s 94us/step - loss: 0.0136 - mean_absolute_error: 0.0898 - val_loss: 0.0143 - val_mean_absolute_error: 0.0906\n",
      "Epoch 200/200\n",
      "1406/1406 [==============================] - 0s 80us/step - loss: 0.0137 - mean_absolute_error: 0.0895 - val_loss: 0.0135 - val_mean_absolute_error: 0.0898\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "#K.clear_session()\n",
    "#keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=100)\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(5, activation='relu', kernel_initializer='normal',input_shape=(10,)))\n",
    "model.add(layers.Dense(2, activation='relu', kernel_initializer='normal'))\n",
    "model.add(layers.Dense(1,kernel_initializer='normal'))\n",
    "model.compile(optimizer=\"adam\", metrics=['mae'], loss='mse')\n",
    "history=model.fit(X_train,y_train,epochs=200, batch_size=15,validation_split=0.2)\n",
    "model.summary()\n",
    "from keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 440, index implies 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-b9c610b07352>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTPR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeatur\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TPR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTPR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTPR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    247\u001b[0m                             \u001b[1;34m'Length of passed values is {val}, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                             \u001b[1;34m'index implies {ind}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                             .format(val=len(data), ind=len(index)))\n\u001b[0m\u001b[0;32m    250\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of passed values is 440, index implies 2"
     ]
    }
   ],
   "source": [
    "TPR=model.predict(X_test)\n",
    "featur=['value','TPR']\n",
    "TPR = pd.Series(TPR, index=featur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0880863984877413"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_loss,test_acc=model.evaluate(X_test,y_test,verbose=1)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1663    0.522014\n",
       "1699    0.216399\n",
       "960     0.695921\n",
       "1434    0.727950\n",
       "1634    0.336692\n",
       "232     0.434247\n",
       "2029    0.576223\n",
       "1568    0.600352\n",
       "1757    0.186292\n",
       "766     0.263658\n",
       "1881    0.496891\n",
       "1969    0.336400\n",
       "1339    0.270301\n",
       "238     0.263475\n",
       "1715    0.379891\n",
       "935     0.554740\n",
       "946     0.710547\n",
       "1049    0.503378\n",
       "1133    0.438084\n",
       "552     0.520256\n",
       "712     0.431509\n",
       "1518    0.572755\n",
       "1955    0.400741\n",
       "2099    0.384400\n",
       "1750    0.442181\n",
       "999     0.661331\n",
       "1589    0.533043\n",
       "1877    0.602643\n",
       "1622    0.426699\n",
       "1933    0.553317\n",
       "          ...   \n",
       "638     0.316747\n",
       "886     0.597124\n",
       "165     0.687194\n",
       "805     0.920154\n",
       "51      0.820034\n",
       "1931    0.439341\n",
       "287     0.443262\n",
       "19      0.883961\n",
       "1820    0.497500\n",
       "1833    0.752082\n",
       "1957    0.543941\n",
       "1220    0.825548\n",
       "450     0.869103\n",
       "185     0.688516\n",
       "993     0.590455\n",
       "958     0.462470\n",
       "661     0.348391\n",
       "969     0.744432\n",
       "342     0.293742\n",
       "1005    0.503098\n",
       "1059    0.646887\n",
       "2140    0.637422\n",
       "1360    0.112188\n",
       "1515    0.561004\n",
       "751     0.372509\n",
       "1299    0.444907\n",
       "1915    0.430946\n",
       "2137    0.729661\n",
       "900     0.558180\n",
       "836     0.979470\n",
       "Name: TPR, Length: 440, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "callbacks=[\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log',\n",
    "        histogram_freq=1, \n",
    "    )\n",
    "]\n",
    "\n",
    "history=model.fit(X_train,y_train,epochs=150, batch_size=10,validation_split=0.2,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "K.clear_session()\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=100)\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(10,)))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=\"adam\", metrics=['mae'], loss='mse')\n",
    "history=model.fit(X_train,y_train,epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def Build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(5, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(2, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='adam', metrics=['mae'], loss='mse')\n",
    "    return model\n",
    "nn=Build_model()\n",
    "nn.fit(X_train,y_train,epochs=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='rmsprop', metrics=['mae'], loss='mse')\n",
    "history=model.fit(X_train,y_train,epochs=1500, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a model\n",
    "from keras.models import model_from_json\n",
    "model_json=model.to_json()\n",
    "with open('model.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5')\n",
    "print('model saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27bd1077908>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuQXGd55/Hvr7vnftPIGusuS7blmyDYMDisCSQhNigXbDawwRCyzoYtLxQGsmy2MEXKAbOkEmfjZAmugLNrlrAhBkKy0RIT4xhMAsQg2RY2si3rYtkaS7ZGljQjzbW759k/+ozcGvdtZHX3WPp9qrrmnLfPOf3MmZ5++r2c9ygiMDMzqyTV7ADMzGzhc7IwM7OqnCzMzKwqJwszM6vKycLMzKpysjAzs6qcLMzMrConCzMzq8rJwszMqso0O4BTZcmSJbF27dpmh2Fm9rLywAMPHIyIgWrbnTbJYu3atWzZsqXZYZiZvaxIeqqW7dwMZWZmVTlZmJlZVU4WZmZWlZOFmZlV5WRhZmZV1TVZSNooabuknZJurLDdOySFpMFkfa2kCUlbk8fn6hmnmZlVVrehs5LSwG3AVcAQsFnSpoh4dM52PcCHgB/OOcSuiLi0XvGZmVnt6lmzuBzYGRG7I2IauBO4psR2nwJuASbrGEtZY1M5bv3Wdh56+nAzXt7M7GWhnsliJbC3aH0oKTtO0mXA6oj4Ron910l6SNJ3Jb2hXkFOZvN85ts7eXhopF4vYWb2slfPK7hVoiyOPymlgD8BfrPEdvuBNRHxvKTXAP9X0oaIGD3hBaTrgesB1qxZc1JBplOFMPMzUWVLM7MzVz1rFkPA6qL1VcC+ovUe4BXAfZL2AK8DNkkajIipiHgeICIeAHYBF8x9gYi4PSIGI2JwYKDq1CYlSYVkMRNOFmZm5dQzWWwG1ktaJ6kVuBbYNPtkRIxExJKIWBsRa4H7gasjYoukgaSDHEnnAuuB3fUIcrZm4WRhZlZe3ZqhIiIn6QbgbiAN3BER2yTdDGyJiE0Vdn8jcLOkHJAH3hcRh+oRZ1qzzVD1OLqZ2emhrrPORsRdwF1zym4qs+3PFS1/Hfh6PWOblUrqVq5ZmJmVd8Zfwf1CzcLJwsysnDM+WaTcwW1mVpWTxWwHt2sWZmZlnfHJAgojovKuWZiZleVkQaHfwqOhzMzKc7KgMCIqXLMwMyvLyYJCJ7dHQ5mZledkQdIM5ZqFmVlZThYURkR5NJSZWXlOFng0lJlZNU4WFPosXLEwMyvPyQJIyRflmZlV4mRB0gzlZGFmVpaTBcnQWfdZmJmV5WRBoWbhZigzs/KcLEiShXOFmVlZThaAhJuhzMwqcLKgcAW3m6HMzMqra7KQtFHSdkk7Jd1YYbt3SApJg0VlH0v22y7pLfWM06OhzMwqq9s9uCWlgduAq4AhYLOkTRHx6JzteoAPAT8sKrsEuBbYAKwA/knSBRGRr0eshYvynCzMzMqpZ83icmBnROyOiGngTuCaEtt9CrgFmCwquwa4MyKmIuJJYGdyvLpwB7eZWWX1TBYrgb1F60NJ2XGSLgNWR8Q35rvvqZQSboYyM6ugnslCJcqOfyJLSgF/AvyX+e5bdIzrJW2RtGV4ePikA02l3AxlZlZJPZPFELC6aH0VsK9ovQd4BXCfpD3A64BNSSd3tX0BiIjbI2IwIgYHBgZOOtC0b35kZlZRPZPFZmC9pHWSWil0WG+afTIiRiJiSUSsjYi1wP3A1RGxJdnuWkltktYB64Ef1SvQlEdDmZlVVLfRUBGRk3QDcDeQBu6IiG2Sbga2RMSmCvtuk/RV4FEgB3ygXiOhwDULM7Nq6pYsACLiLuCuOWU3ldn25+asfxr4dN2CK5JKwXTeycLMrBxfwU0y66xrFmZmZTlZMHudhZOFmVk5Tha4z8LMrBonC0C+B7eZWUVOFkA65Xtwm5lV4mRBMuus+yzMzMpysiCZddY1CzOzspwscM3CzKwaJwt8Pwszs2qcLJhthmp2FGZmC5eTBYXRUL7OwsysPCcL3GdhZlaNkwUeDWVmVo2TBe7gNjOrxsmCpBnKNQszs7KcLJitWTQ7CjOzhcvJAo+GMjOrxsmCwj243WdhZlaekwXu4DYzq6auyULSRknbJe2UdGOJ598n6RFJWyV9T9IlSflaSRNJ+VZJn6tnnL75kZlZZZl6HVhSGrgNuAoYAjZL2hQRjxZt9uWI+Fyy/dXArcDG5LldEXFpveIrVmiGgohAUiNe0szsZaWeNYvLgZ0RsTsipoE7gWuKN4iI0aLVLqApX+/TSYJw5cLMrLR6JouVwN6i9aGk7ASSPiBpF3AL8KGip9ZJekjSdyW9odQLSLpe0hZJW4aHh0860HRyFtxvYWZWWj2TRan2nBd9GkfEbRFxHvBR4HeT4v3Amoi4DPgI8GVJvSX2vT0iBiNicGBg4OQDTWoW7rcwMyutnsliCFhdtL4K2Fdh+zuBtwFExFREPJ8sPwDsAi6oU5ykU7PNUE4WZmal1DNZbAbWS1onqRW4FthUvIGk9UWrvwzsSMoHkg5yJJ0LrAd21yvQtGsWZmYV1W00VETkJN0A3A2kgTsiYpukm4EtEbEJuEHSlUAWOAxcl+z+RuBmSTkgD7wvIg7VK9bUbM3CN0AyMyupbskCICLuAu6aU3ZT0fKHy+z3deDr9YytWDrpXXEzlJlZab6CmxdqFr4BkplZaRWThaS0pP/cqGCaJTV7nYX7LMzMSqqYLCIiz5wL6U5HadcszMwqqqXP4vuSPgt8BRibLYyIB+sWVYN5NJSZWWW1JIsrkp83F5UF8KZTH05zzPZZuGJhZlZa1WQRET/fiECaKckVrlmYmZVRdTSUpD5Jt87OwSTpjyX1NSK4RnGfhZlZZbUMnb0DOAr8WvIYBb5Qz6AazaOhzMwqq6XP4ryIeHvR+iclba1XQM3gmoWZWWW11CwmJP3M7Iqk1wMT9Qup8Wb7LDzdh5lZabXULN4H/GVRP0XxHE6nhePNUK5ZmJmVVDFZSEoBF0bEq2bvJzHn7nanhePNUO6zMDMrqdoV3DPADcny6OmYKMBzQ5mZVVNLn8U9kn5H0mpJi2cfdY+sgdIeDWVmVlEtfRa/lfz8QFFZAOee+nCa44U+iyYHYma2QNXSZ/GeiPh+g+JpilRSv3KfhZlZabX0Wfz3BsXSNGmPhjIzq6iWPotvSXq7lHyinoY8GsrMrLJaksVHgK8BU5JGJR2VVNOoKEkbJW2XtFPSjSWef5+kRyRtlfQ9SZcUPfexZL/tkt5S8290Ejwaysysslpmne05mQNLSgO3AVcBQ8BmSZsi4tGizb4cEZ9Ltr8auBXYmCSNa4ENwArgnyRdkNyM6ZSb7eAOJwszs5LK1iwkvado+fVznruhhmNfDuyMiN0RMQ3cyZy77s25bqOLwigrku3ujIipiHgS2Jkcry5euPlRvV7BzOzlrVIz1EeKlv9sznO/RXUrgb1F60NJ2QkkfUDSLuAW4EPz2fdU8WgoM7PKKiULlVkutV5t/1kv+jSOiNsi4jzgo8DvzmdfSdfP3mdjeHi4hpBKm+3g9mgoM7PSKiWLKLNcar2UIWB10foqYF+F7e8E3jaffSPi9ogYjIjBgYGBGkIqzffgNjOrrFKyuEjSw5IeKVqeXb+whmNvBtZLWieplUKH9abiDSStL1r9ZWBHsrwJuFZSm6R1wHrgRzX+TvMmX2dhZlZRpdFQF7+UA0dELukIvxtIA3dExDZJNwNbImITcIOkK4EsRVOfJ9t9FXgUyAEfqNdIKHAzlJlZNWWTRUQ89VIPHhF3AXfNKbupaPnDFfb9NPDplxpDLTwaysysslouyjvtzY6G8qyzZmalOVngZigzs2rmlSwk9Uv6qXoF0yyzV3B7ug8zs9KqJgtJ90nqTW549GPgC5JurX9ojZPyzY/MzCqqpWbRl0zL8avAFyLiNcCV9Q2rsTzrrJlZZbUki4yk5cCvAd+oczxNcXw0lHOFmVlJtSSLmylcK7ErIjZLOpcXLp47LcyOhvKss2ZmpdUyRfnXKNzPYnZ9N/D2egbVaClP92FmVlEtHdznSvp/koYlHZD098kUHKeNtG9+ZGZWUS3NUF8Gvgosp3Ajoq9RmPTvtOHRUGZmldWSLBQRX4qIXPL4P9Q26+zLxgujoZociJnZAlW2zyK5rgLgO8n9s++kkCTeCfxDA2JrmCRX+ApuM7MyKnVwP0AhOczeiOg/FT0XwKfqFVSjSUJysjAzK6fSrLNlO7EltdQnnOZJSx4NZWZWRs1zQ6ngTZL+J4U72Z1WUil5NJSZWRm1DJ39aUn/A3iKwh3s/gW4qN6BNVpa8mgoM7MyyiYLSZ+WtAP4feAR4DJgOCK+GBGHGxVgo6QEzhVmZqVV6uC+HtgO/DnwjYiYlHTafpymUu6zMDMrp1Iz1DIKtzW9Gtgp6UtAh6SqU4TMkrRR0nZJO5Pht3Of/4ikRyU9LOleSecUPZeXtDV5bJrH73RS0il5NJSZWRmVRkPlgW8C35TUDvwK0Ak8I+neiHh3pQNLSgO3AVdR6BDfLGlTRDxatNlDwGBEjEt6P3ALhes4ACYi4tKT/cXmy6OhzMzKq2k0VERMRsTfRMTbgfUUZqGt5nJgZ0TsjohpChf1XTPnuN+JiPFk9X5gVe2hn1op1yzMzMqa9z24I2I0Ir5Yw6Yrgb1F60NJWTnvpVCTmdUuaYuk+yW9bb5xzldKMOPpPszMSqq5/+EkqERZya/ukt4DDAI/W1S8JiL2JffP+LakRyJi15z9rqfQEc+aNWteUrBp+ToLM7Ny5l2zmIchYHXR+ipg39yNJF0JfBy4OiKmZssjYl/yczdwH4WhuyeIiNsjYjAiBgcGBl5SsKmUr7MwMyunppqFpCuAtcXbR8RfVtltM7A+uffFM8C1wAmd4pIuAz4PbIyIA0Xl/cB4RExJWgK8nkLnd92kfQW3mVlZVZNFMmT2PGArkE+KA6iYLCIiJ+kGCp3haeCOiNgm6WZgS0RsAv4I6Aa+psI9JZ6OiKuBi4HPS5qhUPv5gzmjqE45j4YyMyuvlprFIHBJnMQNqiPiLuCuOWU3FS1fWWa/HwCvnO/rvRQSuGJhZlZaLX0WP6Fwgd5pLe0ruM3MyqqlZrEEeFTSj4DiDuir6xZVE6Q8GsrMrKxaksUn6h3EQpD2aCgzs7KqJouI+G4jAmk2j4YyMyuvlvtZvE7SZknHJE0nE/yNNiK4RpLkKcrNzMqopYP7s8C7gB1AB/Afk7LTSlq4GcrMrIyaLsqLiJ2S0slMtF+Q9IM6x9VwHg1lZlZeLcliXFIrsFXSLcB+oKu+YTWeR0OZmZVXSzPUbyTb3QCMUZjv6e31DKoZPBrKzKy8WkZDPSWpA1geEZ9sQExNkZLvZ2FmVk4to6HeSmFeqH9M1i9txG1OGy2VEnnnCjOzkmpphvoEhbveHQGIiK0UZqA9rXg0lJlZebUki1xEjNQ9kibzaCgzs/JqGQ31E0nvBtKS1gMfAk67obPuszAzK6+WmsUHgQ0UJhH8a2AU+O16BtUMThZmZuXVMhpqnMJtTz9e/3Cax81QZmbllU0W1UY8nXZTlKc8N5SZWTmVahb/BthLoenph4AaElGTpIVrFmZmZVRKFsuAqyhMIvhu4B+Av46IbY0IrNEKNQsnCzOzUsp2cEdEPiL+MSKuA14H7ATuk/TBWg8uaaOk7ZJ2SrqxxPMfkfSopIcl3SvpnKLnrpO0I3lcN8/fa95S8nQfZmblVOzgltQG/DKF2sVa4DPA39ZyYElp4DYKtZMhYLOkTRHxaNFmDwGDETEu6f3ALcA7JS0Gfg8YBAJ4INn38Hx+uflIeyJBM7OyytYsJH2RwvUUrwY+GRGvjYhPRcQzNR77cmBnROyOiGngTuCa4g0i4jvJaCuA+4FVyfJbgHsi4lCSIO4BNtb8W52EVErkZ+r5CmZmL1+Vaha/QWGW2QuAD0nH+7cFRET0Vjn2Sgod5LOGgJ+usP17gW9W2Hfl3B0kXQ9cD7BmzZoq4VSWTuE+CzOzMsomi4io5YK9SkqNnir5aSzpPRSanH52PvtGxO3A7QCDg4Mv6ZPeF+WZmZX3UhNCJUMU7n0xaxWwb+5Gkq6kcMHf1RExNZ99T6WUfFGemVk59UwWm4H1ktYld9q7FjjhQj9JlwGfp5AoDhQ9dTfwZkn9kvqBNydlddOSFll3WpiZlVTTPbhPRkTkJN1A4UM+DdwREdsk3QxsiYhNwB8B3cDXkj6RpyPi6og4JOlTFBIOwM0RcahesQL0trcwmZ1hKpenLZOu50uZmb3s1C1ZAETEXcBdc8puKlq+ssK+dwB31C+6Ey3qagVgZDzL2b1OFmZmxerZDPWy0t/ZAsCRiWyTIzEzW3icLBKLOgo1i8Nj002OxMxs4XGySCxyzcLMrCwni8TxZDHumoWZ2VxOFon+zqQZatw1CzOzuZwsEp2taVrTKY44WZiZvYiTRUISfZ0tboYyMyvByaJIf2eLaxZmZiU4WRRZ1NHKYdcszMxexMmiyKLOFkY8dNbM7EWcLIos6mxxzcLMrAQniyL9na0cHs8Svq+FmdkJnCyKLOpsZTo3w2TWU5WbmRVzsigyexW3m6LMzE7kZFHk+MyzHj5rZnYCJ4sifcnMs74wz8zsRE4WRfq7PPOsmVkpThZFXphM0DULM7NidU0WkjZK2i5pp6QbSzz/RkkPSspJesec5/KStiaPTfWMc1ZfR6FmcfCok4WZWbG63YNbUhq4DbgKGAI2S9oUEY8WbfY08JvA75Q4xEREXFqv+Eppb0lzzlmdPP7saCNf1sxswatbsgAuB3ZGxG4ASXcC1wDHk0VE7EmeWzAXNmxY0ctPnnGyMDMrVs9mqJXA3qL1oaSsVu2Stki6X9LbTm1o5W1Y0cfTh8YZnXQnt5nZrHomC5Uom888GmsiYhB4N/Cnks570QtI1ycJZcvw8PDJxnmCS1b0AvDoPtcuzMxm1TNZDAGri9ZXAftq3Tki9iU/dwP3AZeV2Ob2iBiMiMGBgYGXFm1iQ5IstjlZmJkdV89ksRlYL2mdpFbgWqCmUU2S+iW1JctLgNdT1NdRT2f3tDPQ08a2fSONeDkzs5eFuiWLiMgBNwB3A48BX42IbZJulnQ1gKTXShoC/h3weUnbkt0vBrZI+jHwHeAP5oyiqqsNK3rdDGVmVqSeo6GIiLuAu+aU3VS0vJlC89Tc/X4AvLKesVWyYUUv/7LjIJPZPO0t6WaFYWa2YPgK7hI2rOgjPxM88dzRZodiZrYgOFmU4E5uM7MTOVmUsLq/k562jDu5zcwSThYlpFLi4hW9rlmYmSWcLMrYsKKXx/cfJT/j+3GbmTlZlLFhRR8T2TxPHjzW7FDMzJrOyaIMd3Kbmb3AyaKM88/upjWTcrIwM8PJoqyWdIoLl/Z4RJSZGU4WFW1IRkRFuJPbzM5sThYVbFjRy5HxLPtGJpsdiplZUzlZVHDJij4Atj3jpigzO7M5WVRw8fIeJI+IMjNzsqigszXDuUu6nCzM7IznZFHFhhV9POoRUWZ2hnOyqOKVK/vYNzLJs+7kNrMzmJNFFT93YeHe3vc89lyTIzEzax4niyrOP7ubc5d08a1tzzY7FDOzpqlrspC0UdJ2STsl3Vji+TdKelBSTtI75jx3naQdyeO6esZZiSSu2rCUf931PCMT2WaFYWbWVHVLFpLSwG3ALwKXAO+SdMmczZ4GfhP48px9FwO/B/w0cDnwe5L66xVrNW++ZBm5meC+7QeaFYKZWVPVs2ZxObAzInZHxDRwJ3BN8QYRsSciHgZm5uz7FuCeiDgUEYeBe4CNdYy1ostWL2JZbztf+tenPPWHmZ2R6pksVgJ7i9aHkrJ673vKpVLig79wPlueOszd29zRbWZnnnomC5Uoq/VreU37Srpe0hZJW4aHh+cV3Hy9c3A168/u5g+++RgHj03V9bXMzBaaeiaLIWB10foqYN+p3Dcibo+IwYgYHBgYOOlAa5FJp/jk1RvYNzLJm//kn7n1nif4+63PsOfgmJumzOy0l6njsTcD6yWtA54BrgXeXeO+dwO/X9Sp/WbgY6c+xPm54vwl/MMHf4aP/e0j/Nm3dzCbIzpb06zq72B1fyf5CPYdmWBZXwfnDXRx3kA35w1009/VwuhEjmW97Szra2cmgrZMCklM5fJEcHzdzGyhqVuyiIicpBsofPCngTsiYpukm4EtEbFJ0muBvwP6gbdK+mREbIiIQ5I+RSHhANwcEYfqFet8rF/aw9+8/woms3l2D4/x0N7D7DowxtDhcfYenkDAmsVdPDs6weYnDzGRzZc9VkdLmq62zPFmrfaWFBct66U1k+LYZI6O1jSdrWkyKTF8bIqB7jbevGEZr1zZx3Ojk3x/5/OcO9DFQE8bu4aP8cCew2RngrdduoLO1gxHJ7O0ZlKsXtxJb3uGB58+QndbhouX93LO4k7Gs3n2HByjozVNWkKC5X0dtGZeXOHMzwT5mSj5HEBEIImjk1m+/fgBzjmri0tXLzol59zMmk+nSxPK4OBgbNmypdlhnGBmJnh2dJJdw8cYncjR3Z5h/5EJDhydIpMWh45Nc2wqx/K+DjJpcfDYFI/tH2VmBnraM0zm8oxN5ZnOzTDQ08bug8fYe2ji+PFb0iKbf+Hvd+6SLrIzMydsU05HS5rJpEZTLCXo7WghkxLplMikCsnhwNFJsvmguy3D4q5WFne1clby88hElu/tOEhKkJsJpnKFwW3nDXSxvK+D3o4MbZk0z49Nk83N0JJJ0ZoWFy7r4a2vWsFj+0fZd6QwncrTz4+TmwkuXNbN0t529h2Z5DvbD7C6v5OVi9rZOjTC0OFxCHjD+iWsXtxJSiIlSKeEJFISKxa1s2ZxJw88dZjRyRy97RlGJrK0taS54OxuBnraeHZ0kgf2HOaSFb30dbRw7+MHOG+gm1et6uPZ0Umy+RlEIYkqeY2URFdbhu62DMemckQEPe0ZutoyZHPBwbEpDh6d4sDRKY6MT3P+2T0s6W5l/8gkPe0ZzupqA+BHew5xdDLLta9dw7GpHA89fZjnx6ZZsaiDtWd1svPAMTLpFGsWd7JyUQcPDx3hX3YcpC2TYlV/Bxct72ViOk8+gr6OFnrbW3h2ZJLNew7xipV9vGJlL8+NTrHvyAST2TwrFnXQ2ZpmZCLLtn2jnDfQzWvX9vODXc8zPp2nv7OFRZ2tx3+2t6QYmchyYHSKc87qZFFnKxHB3kMTjE5mWdLdxth0jkNj0xwem+as7laW9raTktg/MsnhsWn6OlvoLzpmOiUms3m27j3C2FSO7rYM3e0ZetpaaG9JMTqZZSo3Q1umUFPPpMSBo1NM52bIRzAzE4xOFq51Wrekm8Pj0xwZz3LB0m562luYmQl2DR9jy1OHefrQOK9c2ce5A11kUuLpQ+NIYnV/B4fHs6QEy/o6yOZmaGtJsay3HYCp3AyjE1lGJrKMTefJ5WdY2ttOf1crTz8/jlRoAThwdIoIWNzVyvlndyNg/2jh9x6ZyDIxnefiFb0s6W7lyHiWrrYMmZQYnczS3ZZhMjvD48+O0t/ZSlty++alve1sWNFLSzp1/L0G8MSBozzx3DG6WtOs6u/k3IEuWtIpJrN5Do9Ps6ijlY7W9El8QhVIeiAiBqtu52Tx8hER7BoeY/uzR+lqS3PFeUt45sgEoxNZ1p7VRV9n4R/mkWdGSKdEX0dLoQZ0cIyR8SyvPmcRE9MzPLp/hMefPUpvewsXLus53gyWnwn2HhpnZCJLLqlJZPNBECztbaezJc2h8WkOjRUeB49Nc2hsipZ0ip+9YIDWTAohNr5iGY8/O8p924c5Mj7N6GSOyWyes7paacukmc7PMJnN88RzR5mZ8/Zb0t2KJIaPvjCI4OLlvewfmWBkIsuFS3s4b6CbiWye7+88eDwxnQoSL0qe9TTb4ljra3a0pMlHMH0Kf+dadbWmCWB8unxNuRKpcKvi2RpqLdunJXI1bAvQ254hAo5O5YDCl54adwUKTcm5fDCdn/+57W7LMBNx0udmviTIpE78oviac/r5+vuvOMnjOVnYAjd0eJzvPjHMK1f2ccHSHgDaWwrfkEbGswwfm6SjNcPKRR3kZ4KpXJ7O1hdaTqdzM0zm8szMBDMBM8m3z3wETw6Psef5cS5bs4jlfe2MTuTo7cgwPp1nx4FjHBqboruthdeu7eehvUcYncjypovOZvfwGE8eHGN5XzvtLWlmIggKiXo2oR6bynF0MkdPeyGWY1M5xqbyZNJioLuNs7pbGehpo6+jhcf2jzI6kWP5onaOTuY4PDbNTAQbkhtrfWXzXpb2tnHF+Us4u6eNPQfH2Xt4nPVndzMTsPfQOE8fGmdVfwc/f9HZZFLimSMT7HjuGN3tGVIqfFsdncjS057hNecsZuveIzx9aJzlve2sWNRBe0uKfUcmmczm6WhNc9GyHh58+gjb9o3w+uR1D49nk2/q04yMZ5nIztDdnuHsnjaePDjGgdEpZiJYv7Sbs7raOHhs6ngtc1FnCwePTTF8dIqZgKW9bZzV1cboZPZ4zePQeJapXJ6WVIrL1ixiSXcbx6Zyhcdkjolsnt6OFlqTb8x7nh9jKjfDqv4OOlrSpFOFGmNPe+GDeffwGP2drfR1tLD9uaMcGJ1kJuCnVvUxuHYxKxd1sG3fCPtHCjXEVf0d5Gdg35EJ+rtamZkJ9o9M0pZJMT6d48mD47RmUvR2ZOhtb6G3o4XutjTpVIp9RyY4PD7NmqQWO5XLM9DdTioFz41O8uBTR0inxAVLC7XIRZ2tZNLikaERRiey9He1Mj6dI5sPetszjE3nSUtctLyHI+OFWsglK3rZPzLJjgNHieD4+3gmYM3iTl6xspfJ7Ax7Do6x++AY07kZutvS9HcVai69HS38xuvOOan/QycLMzOrqtZk4YkEzcysKicLMzOrysnCzMyqcrIwM7OqnCzMzKwqJwszM6vKycLMzKpysjAzs6pOm4vyJA0DT72EQywBDp6icE4lxzU/CzUuWLixOa75WahxwcnFdk5EVL3Hw2mTLF4qSVtquYqx0RzX/CzUuGBVJITYAAAGDklEQVThxua45mehxgX1jc3NUGZmVpWThZmZVeVk8YLbmx1AGY5rfhZqXLBwY3Nc87NQ44I6xuY+CzMzq8o1CzMzq+qMTxaSNkraLmmnpBubGMdqSd+R9JikbZI+nJR/QtIzkrYmj19qUnx7JD2SxLAlKVss6R5JO5Kf/Q2O6cKi87JV0qik327GOZN0h6QDkn5SVFby/KjgM8l77mFJr25wXH8k6fHktf9O0qKkfK2kiaLz9rl6xVUhtrJ/O0kfS87ZdklvaXBcXymKaY+krUl5w85Zhc+IxrzPCncAOzMfQBrYBZwLtAI/Bi5pUizLgVcnyz3AE8AlwCeA31kA52oPsGRO2S3AjcnyjcAfNvlv+SxwTjPOGfBG4NXAT6qdH+CXgG8CAl4H/LDBcb0ZyCTLf1gU19ri7Zp0zkr+7ZL/hR8DbcC65P823ai45jz/x8BNjT5nFT4jGvI+O9NrFpcDOyNid0RMA3cC1zQjkIjYHxEPJstHgceAlc2IZR6uAb6YLH8ReFsTY/kFYFdEvJQLM09aRPwzcGhOcbnzcw3wl1FwP7BI0vJGxRUR34qIXLJ6P7CqHq9dTZlzVs41wJ0RMRURTwI7Kfz/NjQuSQJ+Dfjrerx2JRU+IxryPjvTk8VKYG/R+hAL4ANa0lrgMuCHSdENSTXyjkY39RQJ4FuSHpB0fVK2NCL2Q+GNDJzdpNgAruXEf+CFcM7KnZ+F9L77LQrfPmetk/SQpO9KekOTYir1t1so5+wNwHMRsaOorOHnbM5nREPeZ2d6slCJsqYOD5PUDXwd+O2IGAX+HDgPuBTYT6EK3Ayvj4hXA78IfEDSG5sUx4tIagWuBr6WFC2Uc1bOgnjfSfo4kAP+KinaD6yJiMuAjwBfltTb4LDK/e0WxDkD3sWJX0oafs5KfEaU3bRE2UmfszM9WQwBq4vWVwH7mhQLkloovAn+KiL+FiAinouIfETMAH9Bnare1UTEvuTnAeDvkjiem63WJj8PNCM2CgnswYh4LolxQZwzyp+fpr/vJF0H/Arw65E0cCdNPM8nyw9Q6Be4oJFxVfjbLYRzlgF+FfjKbFmjz1mpzwga9D4705PFZmC9pHXJt9NrgU3NCCRpC/1fwGMRcWtReXEb478FfjJ33wbE1iWpZ3aZQgfpTyicq+uSza4D/r7RsSVO+La3EM5Zotz52QT8+2S0yuuAkdlmhEaQtBH4KHB1RIwXlQ9ISifL5wLrgd2Niit53XJ/u03AtZLaJK1LYvtRI2MDrgQej4ih2YJGnrNynxE06n3WiF78hfygMGLgCQrfCD7exDh+hkIV8WFga/L4JeBLwCNJ+SZgeRNiO5fCSJQfA9tmzxNwFnAvsCP5ubgJsXUCzwN9RWUNP2cUktV+IEvhG917y50fCs0DtyXvuUeAwQbHtZNCW/bs++xzybZvT/6+PwYeBN7ahHNW9m8HfDw5Z9uBX2xkXEn5/wbeN2fbhp2zCp8RDXmf+QpuMzOr6kxvhjIzsxo4WZiZWVVOFmZmVpWThZmZVeVkYWZmVTlZmM2DpLxOnOn2lM1UnMxg2qxrQswqyjQ7ALOXmYmIuLTZQZg1mmsWZqdAco+DP5T0o+RxflJ+jqR7k4nx7pW0JilfqsK9JH6cPK5IDpWW9BfJ/Qq+Jamjab+UWREnC7P56ZjTDPXOoudGI+Jy4LPAnyZln6UwTfRPUZiw7zNJ+WeA70bEqyjcO2FbUr4euC0iNgBHKFwhbNZ0voLbbB4kHYuI7hLle4A3RcTuZLK3ZyPiLEkHKUxZkU3K90fEEknDwKqImCo6xlrgnohYn6x/FGiJiP9W/9/MrDLXLMxOnSizXG6bUqaKlvO4X9EWCCcLs1PnnUU//zVZ/gGF2YwBfh34XrJ8L/B+AEnpJtw3wmxe/K3FbH46JG0tWv/HiJgdPtsm6YcUvoS9Kyn7EHCHpP8KDAP/ISn/MHC7pPdSqEG8n8JMp2YLkvsszE6BpM9iMCIONjsWs3pwM5SZmVXlmoWZmVXlmoWZmVXlZGFmZlU5WZiZWVVOFmZmVpWThZmZVeVkYWZmVf1/nzmuGEo0+R8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist=history.history\n",
    "hist['epoch'] = history.epoch\n",
    "#hist['mean_absolute_error']=history.mean_absolute_error\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Abs Error')\n",
    "plt.plot(hist['epoch'], hist['mean_absolute_error'],label='Train Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RSSI       -0.799458\n",
       "SQ         -6.816540\n",
       "ETX        -0.010123\n",
       "Distance   -0.400445\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reprocessing the data for AE\n",
    "feature1=['RSSI', 'SQ','ETX','Distance']\n",
    "maxi=X_train[feature1].max(axis=0) \n",
    "\n",
    "#Scaling of train dataset\n",
    "X_train[feature1]=X_train[feature1]/maxi\n",
    "\n",
    "mini=X_train[feature1].min(axis=0)\n",
    "\n",
    "#NScaling of test dataset\n",
    "X_test[feature1]=X_test[feature1]/maxi\n",
    "mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1758/1758 [==============================] - 0s 245us/step - loss: 0.4879\n",
      "Epoch 2/100\n",
      "1758/1758 [==============================] - 0s 60us/step - loss: 0.4248\n",
      "Epoch 3/100\n",
      "1758/1758 [==============================] - 0s 57us/step - loss: 0.3936\n",
      "Epoch 4/100\n",
      "1758/1758 [==============================] - 0s 64us/step - loss: 0.3753\n",
      "Epoch 5/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.3617\n",
      "Epoch 6/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.3486\n",
      "Epoch 7/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.3369\n",
      "Epoch 8/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.3271\n",
      "Epoch 9/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.3187\n",
      "Epoch 10/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.3117\n",
      "Epoch 11/100\n",
      "1758/1758 [==============================] - 0s 61us/step - loss: 0.3056\n",
      "Epoch 12/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.3002\n",
      "Epoch 13/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2954\n",
      "Epoch 14/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.2915\n",
      "Epoch 15/100\n",
      "1758/1758 [==============================] - 0s 55us/step - loss: 0.2881\n",
      "Epoch 16/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2853\n",
      "Epoch 17/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2829\n",
      "Epoch 18/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2807\n",
      "Epoch 19/100\n",
      "1758/1758 [==============================] - 0s 70us/step - loss: 0.2788\n",
      "Epoch 20/100\n",
      "1758/1758 [==============================] - 0s 55us/step - loss: 0.2770\n",
      "Epoch 21/100\n",
      "1758/1758 [==============================] - 0s 57us/step - loss: 0.2754\n",
      "Epoch 22/100\n",
      "1758/1758 [==============================] - 0s 74us/step - loss: 0.2739\n",
      "Epoch 23/100\n",
      "1758/1758 [==============================] - 0s 72us/step - loss: 0.2725\n",
      "Epoch 24/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.2713\n",
      "Epoch 25/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2702\n",
      "Epoch 26/100\n",
      "1758/1758 [==============================] - 0s 57us/step - loss: 0.2693\n",
      "Epoch 27/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2685\n",
      "Epoch 28/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2677\n",
      "Epoch 29/100\n",
      "1758/1758 [==============================] - 0s 66us/step - loss: 0.2669\n",
      "Epoch 30/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2664\n",
      "Epoch 31/100\n",
      "1758/1758 [==============================] - 0s 75us/step - loss: 0.2658\n",
      "Epoch 32/100\n",
      "1758/1758 [==============================] - 0s 64us/step - loss: 0.2654\n",
      "Epoch 33/100\n",
      "1758/1758 [==============================] - 0s 58us/step - loss: 0.2651\n",
      "Epoch 34/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2647\n",
      "Epoch 35/100\n",
      "1758/1758 [==============================] - 0s 63us/step - loss: 0.2645\n",
      "Epoch 36/100\n",
      "1758/1758 [==============================] - 0s 72us/step - loss: 0.2643\n",
      "Epoch 37/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2641\n",
      "Epoch 38/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2639\n",
      "Epoch 39/100\n",
      "1758/1758 [==============================] - 0s 60us/step - loss: 0.2638\n",
      "Epoch 40/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.2637\n",
      "Epoch 41/100\n",
      "1758/1758 [==============================] - 0s 65us/step - loss: 0.2635\n",
      "Epoch 42/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2635\n",
      "Epoch 43/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2634\n",
      "Epoch 44/100\n",
      "1758/1758 [==============================] - 0s 54us/step - loss: 0.2633\n",
      "Epoch 45/100\n",
      "1758/1758 [==============================] - 0s 66us/step - loss: 0.2632\n",
      "Epoch 46/100\n",
      "1758/1758 [==============================] - 0s 57us/step - loss: 0.2631\n",
      "Epoch 47/100\n",
      "1758/1758 [==============================] - 0s 57us/step - loss: 0.2631\n",
      "Epoch 48/100\n",
      "1758/1758 [==============================] - 0s 66us/step - loss: 0.2630\n",
      "Epoch 49/100\n",
      "1758/1758 [==============================] - 0s 63us/step - loss: 0.2630\n",
      "Epoch 50/100\n",
      "1758/1758 [==============================] - 0s 56us/step - loss: 0.2630\n",
      "Epoch 51/100\n",
      "1758/1758 [==============================] - 0s 70us/step - loss: 0.2629\n",
      "Epoch 52/100\n",
      "1758/1758 [==============================] - 0s 65us/step - loss: 0.2629\n",
      "Epoch 53/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2629\n",
      "Epoch 54/100\n",
      "1758/1758 [==============================] - 0s 60us/step - loss: 0.2628\n",
      "Epoch 55/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.2628\n",
      "Epoch 56/100\n",
      "1758/1758 [==============================] - 0s 64us/step - loss: 0.2628\n",
      "Epoch 57/100\n",
      "1758/1758 [==============================] - 0s 63us/step - loss: 0.2628\n",
      "Epoch 58/100\n",
      "1758/1758 [==============================] - 0s 61us/step - loss: 0.2628\n",
      "Epoch 59/100\n",
      "1758/1758 [==============================] - 0s 63us/step - loss: 0.2628\n",
      "Epoch 60/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.2627\n",
      "Epoch 61/100\n",
      "1758/1758 [==============================] - 0s 59us/step - loss: 0.2627\n",
      "Epoch 62/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.2627\n",
      "Epoch 63/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 64/100\n",
      "1758/1758 [==============================] - 0s 67us/step - loss: 0.2627\n",
      "Epoch 65/100\n",
      "1758/1758 [==============================] - 0s 65us/step - loss: 0.2627\n",
      "Epoch 66/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.2627\n",
      "Epoch 67/100\n",
      "1758/1758 [==============================] - 0s 74us/step - loss: 0.2627\n",
      "Epoch 68/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2627\n",
      "Epoch 69/100\n",
      "1758/1758 [==============================] - 0s 62us/step - loss: 0.2627\n",
      "Epoch 70/100\n",
      "1758/1758 [==============================] - 0s 64us/step - loss: 0.2627\n",
      "Epoch 71/100\n",
      "1758/1758 [==============================] - 0s 72us/step - loss: 0.2627\n",
      "Epoch 72/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 73/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 74/100\n",
      "1758/1758 [==============================] - 0s 82us/step - loss: 0.2627\n",
      "Epoch 75/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 76/100\n",
      "1758/1758 [==============================] - 0s 76us/step - loss: 0.2627\n",
      "Epoch 77/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2627\n",
      "Epoch 78/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2627\n",
      "Epoch 79/100\n",
      "1758/1758 [==============================] - 0s 59us/step - loss: 0.2626\n",
      "Epoch 80/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 81/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2627\n",
      "Epoch 82/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2626\n",
      "Epoch 83/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2627\n",
      "Epoch 84/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.2627\n",
      "Epoch 85/100\n",
      "1758/1758 [==============================] - 0s 75us/step - loss: 0.2626\n",
      "Epoch 86/100\n",
      "1758/1758 [==============================] - 0s 81us/step - loss: 0.2627\n",
      "Epoch 87/100\n",
      "1758/1758 [==============================] - 0s 77us/step - loss: 0.2627\n",
      "Epoch 88/100\n",
      "1758/1758 [==============================] - 0s 70us/step - loss: 0.2627\n",
      "Epoch 89/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2627\n",
      "Epoch 90/100\n",
      "1758/1758 [==============================] - 0s 74us/step - loss: 0.2627\n",
      "Epoch 91/100\n",
      "1758/1758 [==============================] - 0s 73us/step - loss: 0.2626\n",
      "Epoch 92/100\n",
      "1758/1758 [==============================] - 0s 71us/step - loss: 0.2626\n",
      "Epoch 93/100\n",
      "1758/1758 [==============================] - 0s 79us/step - loss: 0.2626\n",
      "Epoch 94/100\n",
      "1758/1758 [==============================] - 0s 84us/step - loss: 0.2626\n",
      "Epoch 95/100\n",
      "1758/1758 [==============================] - 0s 68us/step - loss: 0.2626\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758/1758 [==============================] - 0s 70us/step - loss: 0.2626\n",
      "Epoch 97/100\n",
      "1758/1758 [==============================] - 0s 66us/step - loss: 0.2626\n",
      "Epoch 98/100\n",
      "1758/1758 [==============================] - 0s 69us/step - loss: 0.2626\n",
      "Epoch 99/100\n",
      "1758/1758 [==============================] - 0s 59us/step - loss: 0.2626\n",
      "Epoch 100/100\n",
      "1758/1758 [==============================] - 0s 76us/step - loss: 0.2626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27bc0603940>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#size of the encoder\n",
    "encoding_dim=4\n",
    "\n",
    "#input shape\n",
    "input_img=Input(shape=(10,))\n",
    "\n",
    "#encoded\n",
    "encoded=Dense(encoding_dim,activation='relu',kernel_initializer='normal')(input_img)\n",
    "\n",
    "#decoded\n",
    "decoded=Dense(10,activation='relu',kernel_initializer='normal')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder=Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#size of the encoder\n",
    "encoding_dim=4\n",
    "\n",
    "#input shape\n",
    "input_img=Input(shape=(10,))\n",
    "\n",
    "#encoded\n",
    "encoded=Dense(8,activation='relu',kernel_initializer='normal')(input_img)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "#decoded\n",
    "decoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded=Dense(10,activation='relu',kernel_initializer='normal')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder=Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.12455511 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.10271834 0.        ]\n",
      " [0.         0.6025282  0.         ... 0.         1.0179375  0.0018743 ]\n",
      " ...\n",
      " [0.         0.7049637  0.         ... 0.         0.         0.        ]\n",
      " [0.         0.68212533 0.         ... 0.         1.0212705  0.00572175]\n",
      " [0.         0.6733233  0.         ... 0.         0.9910491  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json=autoencoder.to_json()\n",
    "with open('autoencoder5000.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "autoencoder.save_weights('autoencoder5000.h5')\n",
    "print('autoencoder saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file=open('autoencoder1.json','r')\n",
    "automodel_json=json_file.read()\n",
    "automodel=model_from_json(automodel_json)\n",
    "automodel.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.68739533, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_imgs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSSI</th>\n",
       "      <th>SQ</th>\n",
       "      <th>ETX</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Area_ParkLOS</th>\n",
       "      <th>Area_ParkNLOS</th>\n",
       "      <th>Area_RESIDENTIAL_IN</th>\n",
       "      <th>Area_RESIDENTIAL_OD</th>\n",
       "      <th>Area_TrackLOS</th>\n",
       "      <th>Area_TrackNLOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>-0.532552</td>\n",
       "      <td>0.107608</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>1.778417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>-0.856909</td>\n",
       "      <td>-2.346020</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>2.135698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.208194</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.505393</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.494283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>-0.402809</td>\n",
       "      <td>0.189396</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>1.490608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-0.402809</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>0.145353</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>0.440521</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>-0.208194</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>0.835594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>-1.051524</td>\n",
       "      <td>-1.691719</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>2.711316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-1.181267</td>\n",
       "      <td>-1.200994</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>1.281242</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0.051292</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>0.352971</td>\n",
       "      <td>1.262748</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>-0.628480</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.041012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-0.402809</td>\n",
       "      <td>0.352971</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.176637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>-0.532552</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>2.294489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.440521</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.156261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.310778</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.080873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>-0.467680</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.625030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>-0.727166</td>\n",
       "      <td>0.189396</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>1.200719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-0.337937</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.203854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>-0.792038</td>\n",
       "      <td>-1.119206</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.908241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>-0.013579</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.339371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>-0.921781</td>\n",
       "      <td>-0.873843</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.051292</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>-0.792038</td>\n",
       "      <td>-0.464905</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>2.641845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.116164</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.282359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>-0.143322</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>1.044008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>-0.208194</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>0.404499</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>-0.467680</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>1.262748</td>\n",
       "      <td>1.371515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>-0.597423</td>\n",
       "      <td>-0.055967</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.390184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.089236</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.492079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.181035</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.304542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>2.256923</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.054060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.867694</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.908211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>0.107608</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.856909</td>\n",
       "      <td>-0.055967</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.497758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.321795</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.016109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>0.375650</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>0.570264</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>-0.301330</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2.711024</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.038715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2.321795</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.908411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.337937</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.157902</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-0.337937</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>-0.597423</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>-0.792038</td>\n",
       "      <td>-0.301330</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.555963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>0.570264</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.076756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.181267</td>\n",
       "      <td>-2.346020</td>\n",
       "      <td>2.366210</td>\n",
       "      <td>0.854689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>-0.402809</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.323479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>-0.597423</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.693565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0.764879</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>-0.792038</td>\n",
       "      <td>-0.792056</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.231552</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>-0.208194</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>0.309598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-0.856909</td>\n",
       "      <td>-0.710268</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>1.177630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>-0.662295</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.321921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>-0.597423</td>\n",
       "      <td>0.352971</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>1.154108</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-1.129448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.440521</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.396131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1.997437</td>\n",
       "      <td>0.680121</td>\n",
       "      <td>-0.282099</td>\n",
       "      <td>-0.841604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RSSI        SQ       ETX  Distance  Area_ParkLOS  Area_ParkNLOS  \\\n",
       "1663 -0.532552  0.107608 -0.282099  1.778417             0              0   \n",
       "1699 -0.856909 -2.346020 -0.282099  2.135698             0              0   \n",
       "960  -0.208194  0.598333 -0.282099  0.015075             0              0   \n",
       "1434  0.505393  0.680121 -0.282099 -0.494283             0              0   \n",
       "1634 -0.402809  0.189396  0.404499  1.490608             0              0   \n",
       "232  -0.402809  0.271183  0.404499  0.145353             1              0   \n",
       "2029  0.440521  0.680121 -0.282099 -1.129448             0              0   \n",
       "1568 -0.208194  0.434758  0.404499  0.835594             0              0   \n",
       "1757 -1.051524 -1.691719  0.404499  2.711316             0              0   \n",
       "766  -1.181267 -1.200994  0.404499  1.281242             0              1   \n",
       "1881  0.051292  0.680121 -0.282099 -1.129448             0              0   \n",
       "1969 -0.662295  0.352971  1.262748 -1.129448             0              0   \n",
       "1339 -0.662295 -0.628480 -0.282099  0.041012             0              0   \n",
       "238  -0.402809  0.352971 -0.282099  0.176637             1              0   \n",
       "1715 -0.532552  0.271183 -0.282099  2.294489             0              0   \n",
       "935   0.440521  0.680121 -0.282099 -0.156261             0              0   \n",
       "946   0.310778  0.680121 -0.282099 -0.080873             0              0   \n",
       "1049 -0.467680  0.516546 -0.282099  0.625030             0              0   \n",
       "1133 -0.727166  0.189396 -0.282099  1.200719             0              0   \n",
       "552  -0.337937  0.598333 -0.282099 -0.203854             0              1   \n",
       "712  -0.792038 -1.119206 -0.282099  0.908241             0              1   \n",
       "1518 -0.013579  0.434758 -0.282099  0.339371             0              0   \n",
       "1955 -0.921781 -0.873843 -0.282099 -1.129448             0              0   \n",
       "2099  0.051292  0.598333 -0.282099 -1.129448             0              0   \n",
       "1750 -0.792038 -0.464905 -0.282099  2.641845             0              0   \n",
       "999   0.116164  0.680121 -0.282099  0.282359             0              0   \n",
       "1589 -0.143322  0.516546 -0.282099  1.044008             0              0   \n",
       "1877 -0.208194  0.680121  0.404499 -1.129448             0              0   \n",
       "1622 -0.467680  0.516546  1.262748  1.371515             0              0   \n",
       "1933 -0.662295  0.516546 -0.282099 -1.129448             0              0   \n",
       "...        ...       ...       ...       ...           ...            ...   \n",
       "638  -0.597423 -0.055967 -0.282099  0.390184             0              1   \n",
       "886   1.089236  0.680121 -0.282099 -0.492079             0              0   \n",
       "165   0.181035  0.680121 -0.282099 -0.304542             1              0   \n",
       "805   2.256923  0.680121 -0.282099 -1.054060             0              0   \n",
       "51    1.867694  0.680121 -0.282099 -0.908211             1              0   \n",
       "1931 -0.662295  0.107608 -0.282099 -1.129448             0              0   \n",
       "287  -0.856909 -0.055967 -0.282099  0.497758             1              0   \n",
       "19    2.321795  0.680121 -0.282099 -1.016109             1              0   \n",
       "1820  0.375650  0.680121 -0.282099 -1.129448             0              0   \n",
       "1833  0.570264  0.680121 -0.282099 -1.129448             0              0   \n",
       "1957 -0.662295 -0.301330 -0.282099 -1.129448             0              0   \n",
       "1220  2.711024  0.680121 -0.282099 -1.038715             0              0   \n",
       "450   2.321795  0.680121 -0.282099 -0.908411             0              1   \n",
       "185  -0.337937  0.680121 -0.282099 -0.157902             1              0   \n",
       "993  -0.337937  0.271183 -0.282099  0.241238             0              0   \n",
       "958  -0.597423  0.271183 -0.282099  0.001368             0              0   \n",
       "661  -0.792038 -0.301330 -0.282099  0.555963             0              1   \n",
       "969   0.570264  0.680121 -0.282099  0.076756             0              0   \n",
       "342  -1.181267 -2.346020  2.366210  0.854689             1              0   \n",
       "1005 -0.402809  0.434758 -0.282099  0.323479             0              0   \n",
       "1059 -0.597423  0.271183 -0.282099  0.693565             0              0   \n",
       "2140  0.764879  0.680121 -0.282099 -1.129448             0              0   \n",
       "1360 -0.792038 -0.792056 -0.282099  0.231552             0              0   \n",
       "1515 -0.208194  0.434758 -0.282099  0.309598             0              0   \n",
       "751  -0.856909 -0.710268 -0.282099  1.177630             0              1   \n",
       "1299 -0.662295  0.434758 -0.282099 -0.321921             0              0   \n",
       "1915 -0.597423  0.352971 -0.282099 -1.129448             0              0   \n",
       "2137  1.154108  0.680121 -0.282099 -1.129448             0              0   \n",
       "900   0.440521  0.680121 -0.282099 -0.396131             0              0   \n",
       "836   1.997437  0.680121 -0.282099 -0.841604             0              0   \n",
       "\n",
       "      Area_RESIDENTIAL_IN  Area_RESIDENTIAL_OD  Area_TrackLOS  Area_TrackNLOS  \n",
       "1663                    0                    1              0               0  \n",
       "1699                    0                    1              0               0  \n",
       "960                     0                    0              1               0  \n",
       "1434                    0                    1              0               0  \n",
       "1634                    0                    1              0               0  \n",
       "232                     0                    0              0               0  \n",
       "2029                    1                    0              0               0  \n",
       "1568                    0                    1              0               0  \n",
       "1757                    0                    1              0               0  \n",
       "766                     0                    0              0               0  \n",
       "1881                    1                    0              0               0  \n",
       "1969                    1                    0              0               0  \n",
       "1339                    0                    0              0               1  \n",
       "238                     0                    0              0               0  \n",
       "1715                    0                    1              0               0  \n",
       "935                     0                    0              1               0  \n",
       "946                     0                    0              1               0  \n",
       "1049                    0                    0              1               0  \n",
       "1133                    0                    0              1               0  \n",
       "552                     0                    0              0               0  \n",
       "712                     0                    0              0               0  \n",
       "1518                    0                    1              0               0  \n",
       "1955                    1                    0              0               0  \n",
       "2099                    1                    0              0               0  \n",
       "1750                    0                    1              0               0  \n",
       "999                     0                    0              1               0  \n",
       "1589                    0                    1              0               0  \n",
       "1877                    1                    0              0               0  \n",
       "1622                    0                    1              0               0  \n",
       "1933                    1                    0              0               0  \n",
       "...                   ...                  ...            ...             ...  \n",
       "638                     0                    0              0               0  \n",
       "886                     0                    0              1               0  \n",
       "165                     0                    0              0               0  \n",
       "805                     0                    0              1               0  \n",
       "51                      0                    0              0               0  \n",
       "1931                    1                    0              0               0  \n",
       "287                     0                    0              0               0  \n",
       "19                      0                    0              0               0  \n",
       "1820                    1                    0              0               0  \n",
       "1833                    1                    0              0               0  \n",
       "1957                    1                    0              0               0  \n",
       "1220                    0                    0              0               1  \n",
       "450                     0                    0              0               0  \n",
       "185                     0                    0              0               0  \n",
       "993                     0                    0              1               0  \n",
       "958                     0                    0              1               0  \n",
       "661                     0                    0              0               0  \n",
       "969                     0                    0              1               0  \n",
       "342                     0                    0              0               0  \n",
       "1005                    0                    0              1               0  \n",
       "1059                    0                    0              1               0  \n",
       "2140                    1                    0              0               0  \n",
       "1360                    0                    0              0               1  \n",
       "1515                    0                    1              0               0  \n",
       "751                     0                    0              0               0  \n",
       "1299                    0                    0              0               1  \n",
       "1915                    1                    0              0               0  \n",
       "2137                    1                    0              0               0  \n",
       "900                     0                    0              1               0  \n",
       "836                     0                    0              1               0  \n",
       "\n",
       "[440 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=2 && 3\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
